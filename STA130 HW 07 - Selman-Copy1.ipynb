{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2940d32",
   "metadata": {},
   "source": [
    "# **Pre-Lecture**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758143b0",
   "metadata": {},
   "source": [
    "## Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303bd434",
   "metadata": {},
   "source": [
    "1. The difference between Simple Linear Regression and Multiple Linear Regression is, SLR uses only one predictor variable to model the relationship with the outcome variable. MLR uses two or more predictor variables to model the relationship with the outcome variable. <br>\n",
    "\n",
    "   (a) SLR aims to find the line of best fit, and MLR aims to find the plane of best fit. <br>\n",
    "   \n",
    "   (b) Benefits of MLR over SLR: <br>\n",
    "   \n",
    "       1. Can model complex relationships  \n",
    "       \n",
    "       2. Increased predictive power   \n",
    "       \n",
    "       3.  Can understand individual predictor effects: MLR allows you to isolate the effect of a specific predictor variable on the outcome while controlling for the influence of other predictors.  \n",
    "       \n",
    "        4. Modeling Non-linear Relationships: MLR can model some non-linear relationships by incorporating transformed predictor variables.  \n",
    "        \n",
    "        5. MLR can seamlessly handle categorical variables (variables with distinct categories) using indicator variables. MLR expands gthe range of questions I can investigate. SLR struggles with categorical variables. \n",
    "\n",
    "2. A continuous variable in SLR are numeric variables that can take on a wide range of values within a given interval. They're used as predictor variables and help model a continous linear relationship with the outcome variable. An indicator variable (dummy variables) are binary variables used to represent categorical data. They indicate whether a particular category is present or absent for a given observation. Indicator variables allow you to integrate categorical data into regression models. \n",
    "\n",
    "        (a) Continuous variable linear form: \n",
    "            outcome = β0 + β1(predictor + ε) \n",
    "            \n",
    "        (b) Indicator variable linear form: \n",
    "            Categorical_data = β0 + β1(indicator_B + β2)(indicator_C + ε)\n",
    "            \n",
    "3. When a single indicator variable is introduced alongside a continuous variable in a MlR, then the model can now capture potential differences in the average outcome between these two groups, even when the continuous predictor is held constant: what graphically happens to the model is a new model is created in which different intercepts for the two groups represented by the indicator variable is now allowed.\n",
    "\n",
    "        (a) Simple Linear Regression: Y_i = β0 + β1 * x_i + ε_i\n",
    "\n",
    "        (b) Multiple Linear Regression: Y_i = β0 + β1 * X_1i + β2 * X_2i + ... + βk * X_ki + ε_i\n",
    "\n",
    "        (c) Mathematical differences: MLR has multiple predictor variables, and each have their own slope coefficients. SLR has one predictor variable and one slope coefficient. MLR is an expansion of SLR by allowing for the consideration of multiple predictors on the outcome variable. \n",
    "\n",
    "4. The effect of adding an interaction between a continuous and an indicator variable in MLR is, it allows the slope of the relationship between the continuous predictor and the outcome to vary depending on the group membership indicated by the indicator variable. The effect of the continuous predictor on the outcome is no longer constant across all groups but now differs depending on the specific category of the indicator variable. \n",
    "\n",
    "        (a) Without interaction: Y = β0 + β1 * x + β2 * k + ε \n",
    "        1. β1 represents the constant effect across all categories\n",
    "    \n",
    "        (b) With interaction: Y = β0 + β1 * x + β2 * k + β3 * x * k + ε\n",
    "        1. β3 captures the difference in slopes now present with an interaction.\n",
    "\n",
    "5. When a Multiple Linear Regression model is based only on indicator variables derived from a single non-binary categorical varaible, it performs group comparisons, similar to an ANOVA (analysis of variance) test. \n",
    "\n",
    "        (a) The non-binary categorical variable extends the use of indicator variables from a simple two-group comparison to situations involving more than two groups. \n",
    "       \n",
    "        (b) For a categorical predictor variable, the creation of K-1 binary indicator variables is necessary, where K represents the number of categories. This process is how one avoids redundancy. Knowing the values of K-1 indicator variables automatically determines the value of the remaining indicator variable. \n",
    "\n",
    "        (c) The linear form: Y = β0 + β1 * 1_[B] + β2 * 1_[C] + ε\n",
    "            1. A, B, and C represent three different groups. \n",
    "            \n",
    "        (d) The model's intercept (β0) represents the mean of the baseline group, which is the group for which all indicator variables are 0. The coefficients for the remaining indicator variables (β1, β2, ... , βn) represent the differences in means between each respective group and the baseline group. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d824ff",
   "metadata": {},
   "source": [
    "## Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca13d275",
   "metadata": {},
   "source": [
    "1. The outcome variable would be the effectiveness of the advertising campaigns, which would need to be specifically defined (sales revenue, web traffic, or some quantifiable metric that reflects the success of advertising).\n",
    "\n",
    "2. The predictor variable would be the amount spent on TV advertising and the amount spent on online advertising, both of which are continuous variables. \n",
    "\n",
    "Meaningful Interactions: \n",
    "\n",
    "1. A potential meaningful interaction could be that a certain level of spending on online advertising might enhance the effectiveness of TV ads. Similarly, low online ad spending could diminish the impact of TV ads. \n",
    "\n",
    "        (a) Continuous Linear Forms without interaction: \n",
    "        Sales = β0 + β1 * TV_Spending + β2 * Online_Spending + ε\n",
    "        \n",
    "            1. β1 captures the average change in sales for a marginal increase in TV spending, holding online spending constant. β2 reflects the average change in sales for a marginal increase in online spending, holding TV spending constant. This model assumes β1 and β2 are independent of each other. \n",
    "        \n",
    "        (b) Continuous Linear Forms with interaction: \n",
    "        Sales = β0 + β1 * TV_Spending + β2 * Online_Spending + β3 * (TV_Spending * Online_Spending) + ε\n",
    "            1. β1 now represents the effect of TV spending on sales when online spending is 0 (baseline group)\n",
    "            2. β2 represents the effect of online spending on sales when TV spending is zero\n",
    "            \n",
    "            3. β3 represents the interaction effect, quantifying how the effect of TV spending on sales changes for each unit increase in online spending. A positive β3 would indicate a synergistic effect, while a negative β3 would suggest a dampening effect.\n",
    "            \n",
    "        (c) Binary Linear Form, No interaction: \n",
    "        Sales = β0 + β1 * TV_High + β2 * Online_High + ε \n",
    "            1. TV_high and Online_High are indicator variables. TV_High = 1 if TV budget is high, 0 if low. Online_High = 1 if online budget is high, 0 if low. \n",
    "            \n",
    "        (d) Binary Linear form, With Interaction\n",
    "        Sales = β0 + β1 * TV_High + β2 * Online_High + β3 * (TV_High * Online_High) + ε\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "931f20e1",
   "metadata": {},
   "source": [
    "## Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c1d5ce36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.509889\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:               survived   No. Observations:                  712\n",
      "Model:                          Logit   Df Residuals:                      707\n",
      "Method:                           MLE   Df Model:                            4\n",
      "Date:                Fri, 15 Nov 2024   Pseudo R-squ.:                  0.2444\n",
      "Time:                        01:54:12   Log-Likelihood:                -363.04\n",
      "converged:                       True   LL-Null:                       -480.45\n",
      "Covariance Type:            nonrobust   LLR p-value:                 1.209e-49\n",
      "======================================================================================\n",
      "                         coef    std err          z      P>|z|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------------\n",
      "Intercept              2.2046      0.322      6.851      0.000       1.574       2.835\n",
      "sex_male[T.True]      -2.4760      0.191    -12.976      0.000      -2.850      -2.102\n",
      "embarked_Q[T.True]    -1.8156      0.535     -3.393      0.001      -2.864      -0.767\n",
      "embarked_S[T.True]    -1.0069      0.237     -4.251      0.000      -1.471      -0.543\n",
      "age                   -0.0081      0.007     -1.233      0.217      -0.021       0.005\n",
      "======================================================================================\n",
      "Intercept             2.204585\n",
      "sex_male[T.True]     -2.475962\n",
      "embarked_Q[T.True]   -1.815592\n",
      "embarked_S[T.True]   -1.006949\n",
      "age                  -0.008079\n",
      "dtype: float64\n",
      "['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_cache', '_data_attr', '_data_in_cache', '_get_endog_name', '_get_robustcov_results', '_get_wald_nonlinear', '_transform_predict_exog', '_use_t', 'aic', 'bic', 'bse', 'conf_int', 'converged', 'cov_kwds', 'cov_params', 'cov_type', 'df_model', 'df_resid', 'f_test', 'fittedvalues', 'get_distribution', 'get_influence', 'get_margeff', 'get_prediction', 'im_ratio', 'info_criteria', 'initialize', 'k_constant', 'llf', 'llnull', 'llr', 'llr_pvalue', 'load', 'method', 'mle_retvals', 'mle_settings', 'model', 'nobs', 'normalized_cov_params', 'params', 'pred_table', 'predict', 'prsquared', 'pvalues', 'remove_data', 'resid_dev', 'resid_generalized', 'resid_pearson', 'resid_response', 'save', 'scale', 'score_test', 'set_null_options', 'summary', 'summary2', 't_test', 't_test_pairwise', 'tvalues', 'use_t', 'wald_test', 'wald_test_terms']\n",
      "                          OR  Lower CI   Upper CI\n",
      "Intercept           9.066489  4.825321  17.035387\n",
      "sex_male[T.True]    0.084082  0.057848   0.122213\n",
      "embarked_Q[T.True]  0.162742  0.057027   0.464428\n",
      "embarked_S[T.True]  0.365332  0.229654   0.581167\n",
      "age                 0.991954  0.979300   1.004771\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.609629\n",
      "         Iterations 5\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:               survived   No. Observations:                  712\n",
      "Model:                          Logit   Df Residuals:                      709\n",
      "Method:                           MLE   Df Model:                            2\n",
      "Date:                Fri, 15 Nov 2024   Pseudo R-squ.:                 0.09657\n",
      "Time:                        01:54:12   Log-Likelihood:                -434.06\n",
      "converged:                       True   LL-Null:                       -480.45\n",
      "Covariance Type:            nonrobust   LLR p-value:                 7.088e-21\n",
      "==========================================================================================================\n",
      "                                             coef    std err          z      P>|z|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "Intercept                                 -1.1558      0.124     -9.293      0.000      -1.400      -0.912\n",
      "C(pclass, Treatment(reference=3))[T.1]     1.7844      0.199      8.987      0.000       1.395       2.174\n",
      "C(pclass, Treatment(reference=3))[T.2]     1.0748      0.197      5.469      0.000       0.690       1.460\n",
      "==========================================================================================================\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:               survived   No. Observations:                  712\n",
      "Model:                          Logit   Df Residuals:                      709\n",
      "Method:                           MLE   Df Model:                            2\n",
      "Date:                Fri, 15 Nov 2024   Pseudo R-squ.:                 0.09657\n",
      "Time:                        01:54:12   Log-Likelihood:                -434.06\n",
      "converged:                       True   LL-Null:                       -480.45\n",
      "Covariance Type:            nonrobust   LLR p-value:                 7.088e-21\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "1st class     -1.1558      0.124     -9.293      0.000      -1.400      -0.912\n",
      "2nd class      1.7844      0.199      8.987      0.000       1.395       2.174\n",
      "3rd class      1.0748      0.197      5.469      0.000       0.690       1.460\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import patsy\n",
    "\n",
    "# Load data from URL\n",
    "titanic = pd.read_csv(\"https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv\")\n",
    "titanic = titanic[[\"Survived\", \"Pclass\", \"Sex\", \"Age\", \"Embarked\"]]\n",
    "titanic = titanic.dropna()\n",
    "\n",
    "# Rename columns to match expected column names\n",
    "titanic.columns = [\"survived\", \"pclass\", \"sex\", \"age\", \"embarked\"]\n",
    "\n",
    "# Convert 'sex' and 'embarked' to dummy variables\n",
    "titanic = pd.get_dummies(titanic, columns=[\"sex\", \"embarked\"], drop_first=True)\n",
    "\n",
    "# Define and fit model\n",
    "log_reg = smf.logit(\"survived ~ sex_male + age + embarked_Q + embarked_S\", data=titanic).fit()\n",
    "\n",
    "# Summary of results\n",
    "print(log_reg.summary())\n",
    "\n",
    "# Inspect parameters\n",
    "print(log_reg.params)\n",
    "\n",
    "# List available methods and attributes of log_reg\n",
    "print(dir(log_reg))\n",
    "\n",
    "# Calculate odds ratios with confidence intervals\n",
    "odds_ratios = pd.DataFrame(\n",
    "    {\n",
    "        \"OR\": log_reg.params,\n",
    "        \"Lower CI\": log_reg.conf_int()[0],\n",
    "        \"Upper CI\": log_reg.conf_int()[1],\n",
    "    }\n",
    ")\n",
    "odds_ratios = np.exp(odds_ratios)\n",
    "print(odds_ratios)\n",
    "\n",
    "# Using patsy for matrix creation\n",
    "y, X = patsy.dmatrices(\"survived ~ sex_male + age + embarked_Q + embarked_S\", data=titanic, return_type=\"dataframe\")\n",
    "\n",
    "formula = \"survived ~ C(pclass, Treatment(reference=3))\"\n",
    "log_reg = smf.logit(formula, data=titanic).fit()\n",
    "\n",
    "fit_summary = log_reg.summary().tables[0]\n",
    "\n",
    "print(log_reg.summary())\n",
    "\n",
    "print(log_reg.summary(xname=[\"1st class\", \"2nd class\", \"3rd class\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f1a012d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:               survived   No. Observations:                  712\n",
      "Model:                          Logit   Df Residuals:                      709\n",
      "Method:                           MLE   Df Model:                            2\n",
      "Date:                Fri, 15 Nov 2024   Pseudo R-squ.:                 0.09657\n",
      "Time:                        01:54:12   Log-Likelihood:                -434.06\n",
      "converged:                       True   LL-Null:                       -480.45\n",
      "Covariance Type:            nonrobust   LLR p-value:                 7.088e-21\n",
      "==========================================================================================================\n",
      "                                             coef    std err          z      P>|z|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "Intercept                                 -1.1558      0.124     -9.293      0.000      -1.400      -0.912\n",
      "C(pclass, Treatment(reference=3))[T.1]     1.7844      0.199      8.987      0.000       1.395       2.174\n",
      "C(pclass, Treatment(reference=3))[T.2]     1.0748      0.197      5.469      0.000       0.690       1.460\n",
      "==========================================================================================================\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:               survived   No. Observations:                  712\n",
      "Model:                          Logit   Df Residuals:                      709\n",
      "Method:                           MLE   Df Model:                            2\n",
      "Date:                Fri, 15 Nov 2024   Pseudo R-squ.:                 0.09657\n",
      "Time:                        01:54:12   Log-Likelihood:                -434.06\n",
      "converged:                       True   LL-Null:                       -480.45\n",
      "Covariance Type:            nonrobust   LLR p-value:                 7.088e-21\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "1st class     -1.1558      0.124     -9.293      0.000      -1.400      -0.912\n",
      "2nd class      1.7844      0.199      8.987      0.000       1.395       2.174\n",
      "3rd class      1.0748      0.197      5.469      0.000       0.690       1.460\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "print(log_reg.summary())\n",
    "\n",
    "print(log_reg.summary(xname=[\"1st class\", \"2nd class\", \"3rd class\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9100eba0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Pretend model coefficients for a continuous and binary predictor\n",
    "intercept = -1.5\n",
    "coef_continuous = 0.8  # Coefficient for a continuous variable\n",
    "coef_binary = 1.2      # Coefficient for a binary variable\n",
    "\n",
    "# Simulate predictor data\n",
    "np.random.seed(42)\n",
    "continuous_data = np.linspace(0, 10, 100)  # Continuous predictor range\n",
    "binary_data = np.random.choice([0, 1], size=100)  # Binary predictor values (0 or 1)\n",
    "\n",
    "# Calculate linear predictor values (log-odds)\n",
    "log_odds_0 = intercept + coef_continuous * continuous_data  # For binary = 0\n",
    "log_odds_1 = intercept + coef_continuous * continuous_data + coef_binary  # For binary = 1\n",
    "\n",
    "# Simulate random noise for continuous data\n",
    "noise = np.random.normal(0, 1, size=100)\n",
    "continuous_data_noisy = continuous_data + noise\n",
    "\n",
    "# Calculate probabilities from log-odds using logistic transformation\n",
    "prob_0 = 1 / (1 + np.exp(-log_odds_0))  # For binary = 0\n",
    "prob_1 = 1 / (1 + np.exp(-log_odds_1))  # For binary = 1\n",
    "\n",
    "# Create figure and plot the lines and noisy data\n",
    "fig = go.Figure()\n",
    "\n",
    "# Plot line for binary = 0\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=continuous_data, y=prob_0, mode='lines', name='Binary Predictor = 0', line=dict(dash='solid')\n",
    "))\n",
    "\n",
    "# Plot line for binary = 1\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=continuous_data, y=prob_1, mode='lines', name='Binary Predictor = 1', line=dict(dash='dash')\n",
    "))\n",
    "\n",
    "# Plot noisy data points for binary = 0\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=continuous_data_noisy[binary_data == 0],\n",
    "    y=prob_0[binary_data == 0],\n",
    "    mode='markers',\n",
    "    name='Noisy Data (Binary = 0)',\n",
    "    marker=dict(color='blue', opacity=0.5)\n",
    "))\n",
    "\n",
    "# Plot noisy data points for binary = 1\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=continuous_data_noisy[binary_data == 1],\n",
    "    y=prob_1[binary_data == 1],\n",
    "    mode='markers',\n",
    "    name='Noisy Data (Binary = 1)',\n",
    "    marker=dict(color='red', opacity=0.5)\n",
    "))\n",
    "\n",
    "# Update layout for better visualization\n",
    "fig.update_layout(\n",
    "    title=\"Logistic Regression: Simulated Probabilities with Continuous and Binary Predictors\",\n",
    "    xaxis_title=\"Continuous Predictor\",\n",
    "    yaxis_title=\"Probability\",\n",
    "    yaxis=dict(range=[0, 1]),  # Probability range\n",
    ")\n",
    "\n",
    "fig.show(renderer=\"png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70cd321a",
   "metadata": {},
   "source": [
    "### Model Linear Approximation: \n",
    "#### Survival Probability = $B_0$ + $B_1$ (sex_male) + $B_2$(age) + $B_3$(embarked_Q) + $B_4$(embarked_s) \n",
    "\n",
    "1. The continuous predictor coefficient ($B_1$) represents the change in predicted outcome for each marginal increase in the continuous predictor variable while assuming the binary predictor remains constant. \n",
    "\n",
    "2. The Binary Predictor coefficient ($B_2$) shows how the outcome shifts when moving between binary predictor states (which are 0 to 1) while keeping the continuous predictor constant. \n",
    "\n",
    "3. Viewing logistical model as a Multivariable Linear Regression Model would mean translating the following relationships as: \n",
    "\n",
    "        (a) The continuous predictor linearly  affects the outcome in a similar fashion to linear regression, but here it linearly affects the log odds. \n",
    "        \n",
    "        (b) The binary predictor changes the intercept between two groups, shifting the probabilities between 0 to 1. \n",
    "        \n",
    "In context of the Titanic Dataset... \n",
    "\n",
    "1. $B_0$ (AKA the intercept) represents the baseline level of survival for a hypothetical reference group (female passengers, with age 0, embarking from Cherbourg). \n",
    "\n",
    "2. $B_1$ (Sex, male coefficient) represents the change in the predicted survival level when the passenger is male instead of female. \n",
    "\n",
    "3. $B_2$ (age, continunous coefficient) represents the impact of each additional year of age on the predicted survival level. \n",
    "\n",
    "4. $B_3$ and $B_4$ (embarkation location, Queenstown and Southampton respectively) represents the impact of emarkation location on predicted survival level. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7d6657",
   "metadata": {},
   "source": [
    "## Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ac1b1d0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#</th>\n",
       "      <th>Name</th>\n",
       "      <th>Type 1</th>\n",
       "      <th>Type 2</th>\n",
       "      <th>HP</th>\n",
       "      <th>Attack</th>\n",
       "      <th>Defense</th>\n",
       "      <th>Sp. Atk</th>\n",
       "      <th>Sp. Def</th>\n",
       "      <th>Speed</th>\n",
       "      <th>Generation</th>\n",
       "      <th>Legendary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Bulbasaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>45</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Ivysaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>60</td>\n",
       "      <td>62</td>\n",
       "      <td>63</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Venusaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>80</td>\n",
       "      <td>82</td>\n",
       "      <td>83</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>VenusaurMega Venusaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>80</td>\n",
       "      <td>100</td>\n",
       "      <td>123</td>\n",
       "      <td>122</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Charmander</td>\n",
       "      <td>Fire</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39</td>\n",
       "      <td>52</td>\n",
       "      <td>43</td>\n",
       "      <td>60</td>\n",
       "      <td>50</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>719</td>\n",
       "      <td>Diancie</td>\n",
       "      <td>Rock</td>\n",
       "      <td>Fairy</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>150</td>\n",
       "      <td>100</td>\n",
       "      <td>150</td>\n",
       "      <td>50</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>719</td>\n",
       "      <td>DiancieMega Diancie</td>\n",
       "      <td>Rock</td>\n",
       "      <td>Fairy</td>\n",
       "      <td>50</td>\n",
       "      <td>160</td>\n",
       "      <td>110</td>\n",
       "      <td>160</td>\n",
       "      <td>110</td>\n",
       "      <td>110</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>720</td>\n",
       "      <td>HoopaHoopa Confined</td>\n",
       "      <td>Psychic</td>\n",
       "      <td>Ghost</td>\n",
       "      <td>80</td>\n",
       "      <td>110</td>\n",
       "      <td>60</td>\n",
       "      <td>150</td>\n",
       "      <td>130</td>\n",
       "      <td>70</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>720</td>\n",
       "      <td>HoopaHoopa Unbound</td>\n",
       "      <td>Psychic</td>\n",
       "      <td>Dark</td>\n",
       "      <td>80</td>\n",
       "      <td>160</td>\n",
       "      <td>60</td>\n",
       "      <td>170</td>\n",
       "      <td>130</td>\n",
       "      <td>80</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>721</td>\n",
       "      <td>Volcanion</td>\n",
       "      <td>Fire</td>\n",
       "      <td>Water</td>\n",
       "      <td>80</td>\n",
       "      <td>110</td>\n",
       "      <td>120</td>\n",
       "      <td>130</td>\n",
       "      <td>90</td>\n",
       "      <td>70</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>800 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       #                   Name   Type 1  Type 2  HP  Attack  Defense  \\\n",
       "0      1              Bulbasaur    Grass  Poison  45      49       49   \n",
       "1      2                Ivysaur    Grass  Poison  60      62       63   \n",
       "2      3               Venusaur    Grass  Poison  80      82       83   \n",
       "3      3  VenusaurMega Venusaur    Grass  Poison  80     100      123   \n",
       "4      4             Charmander     Fire     NaN  39      52       43   \n",
       "..   ...                    ...      ...     ...  ..     ...      ...   \n",
       "795  719                Diancie     Rock   Fairy  50     100      150   \n",
       "796  719    DiancieMega Diancie     Rock   Fairy  50     160      110   \n",
       "797  720    HoopaHoopa Confined  Psychic   Ghost  80     110       60   \n",
       "798  720     HoopaHoopa Unbound  Psychic    Dark  80     160       60   \n",
       "799  721              Volcanion     Fire   Water  80     110      120   \n",
       "\n",
       "     Sp. Atk  Sp. Def  Speed  Generation  Legendary  \n",
       "0         65       65     45           1      False  \n",
       "1         80       80     60           1      False  \n",
       "2        100      100     80           1      False  \n",
       "3        122      120     80           1      False  \n",
       "4         60       50     65           1      False  \n",
       "..       ...      ...    ...         ...        ...  \n",
       "795      100      150     50           6       True  \n",
       "796      160      110    110           6       True  \n",
       "797      150      130     70           6       True  \n",
       "798      170      130     80           6       True  \n",
       "799      130       90     70           6       True  \n",
       "\n",
       "[800 rows x 12 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/KeithGalli/pandas/master/pokemon_data.csv\"\n",
    "# fail https://github.com/KeithGalli/pandas/blob/master/pokemon_data.csv\n",
    "pokeaman = pd.read_csv(url) \n",
    "pokeaman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5dd06aa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>HP</td>        <th>  R-squared:         </th> <td>   0.176</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.164</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   15.27</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 15 Nov 2024</td> <th>  Prob (F-statistic):</th> <td>3.50e-27</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>01:54:12</td>     <th>  Log-Likelihood:    </th> <td> -3649.4</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   800</td>      <th>  AIC:               </th> <td>   7323.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   788</td>      <th>  BIC:               </th> <td>   7379.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    11</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                 <td></td>                    <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                       <td>   26.8971</td> <td>    5.246</td> <td>    5.127</td> <td> 0.000</td> <td>   16.599</td> <td>   37.195</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Generation)[T.2]</th>              <td>   20.0449</td> <td>    7.821</td> <td>    2.563</td> <td> 0.011</td> <td>    4.692</td> <td>   35.398</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Generation)[T.3]</th>              <td>   21.3662</td> <td>    6.998</td> <td>    3.053</td> <td> 0.002</td> <td>    7.629</td> <td>   35.103</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Generation)[T.4]</th>              <td>   31.9575</td> <td>    8.235</td> <td>    3.881</td> <td> 0.000</td> <td>   15.793</td> <td>   48.122</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Generation)[T.5]</th>              <td>    9.4926</td> <td>    7.883</td> <td>    1.204</td> <td> 0.229</td> <td>   -5.982</td> <td>   24.968</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Generation)[T.6]</th>              <td>   22.2693</td> <td>    8.709</td> <td>    2.557</td> <td> 0.011</td> <td>    5.173</td> <td>   39.366</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Def\")</th>                    <td>    0.5634</td> <td>    0.071</td> <td>    7.906</td> <td> 0.000</td> <td>    0.423</td> <td>    0.703</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Def\"):C(Generation)[T.2]</th> <td>   -0.2350</td> <td>    0.101</td> <td>   -2.316</td> <td> 0.021</td> <td>   -0.434</td> <td>   -0.036</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Def\"):C(Generation)[T.3]</th> <td>   -0.3067</td> <td>    0.093</td> <td>   -3.300</td> <td> 0.001</td> <td>   -0.489</td> <td>   -0.124</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Def\"):C(Generation)[T.4]</th> <td>   -0.3790</td> <td>    0.105</td> <td>   -3.600</td> <td> 0.000</td> <td>   -0.586</td> <td>   -0.172</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Def\"):C(Generation)[T.5]</th> <td>   -0.0484</td> <td>    0.108</td> <td>   -0.447</td> <td> 0.655</td> <td>   -0.261</td> <td>    0.164</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Def\"):C(Generation)[T.6]</th> <td>   -0.3083</td> <td>    0.112</td> <td>   -2.756</td> <td> 0.006</td> <td>   -0.528</td> <td>   -0.089</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>337.229</td> <th>  Durbin-Watson:     </th> <td>   1.505</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>2871.522</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.684</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>11.649</td>  <th>  Cond. No.          </th> <td>1.40e+03</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.4e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}                  &        HP        & \\textbf{  R-squared:         } &     0.176   \\\\\n",
       "\\textbf{Model:}                          &       OLS        & \\textbf{  Adj. R-squared:    } &     0.164   \\\\\n",
       "\\textbf{Method:}                         &  Least Squares   & \\textbf{  F-statistic:       } &     15.27   \\\\\n",
       "\\textbf{Date:}                           & Fri, 15 Nov 2024 & \\textbf{  Prob (F-statistic):} &  3.50e-27   \\\\\n",
       "\\textbf{Time:}                           &     01:54:12     & \\textbf{  Log-Likelihood:    } &   -3649.4   \\\\\n",
       "\\textbf{No. Observations:}               &         800      & \\textbf{  AIC:               } &     7323.   \\\\\n",
       "\\textbf{Df Residuals:}                   &         788      & \\textbf{  BIC:               } &     7379.   \\\\\n",
       "\\textbf{Df Model:}                       &          11      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}                &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                                         & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept}                       &      26.8971  &        5.246     &     5.127  &         0.000        &       16.599    &       37.195     \\\\\n",
       "\\textbf{C(Generation)[T.2]}              &      20.0449  &        7.821     &     2.563  &         0.011        &        4.692    &       35.398     \\\\\n",
       "\\textbf{C(Generation)[T.3]}              &      21.3662  &        6.998     &     3.053  &         0.002        &        7.629    &       35.103     \\\\\n",
       "\\textbf{C(Generation)[T.4]}              &      31.9575  &        8.235     &     3.881  &         0.000        &       15.793    &       48.122     \\\\\n",
       "\\textbf{C(Generation)[T.5]}              &       9.4926  &        7.883     &     1.204  &         0.229        &       -5.982    &       24.968     \\\\\n",
       "\\textbf{C(Generation)[T.6]}              &      22.2693  &        8.709     &     2.557  &         0.011        &        5.173    &       39.366     \\\\\n",
       "\\textbf{Q(\"Sp. Def\")}                    &       0.5634  &        0.071     &     7.906  &         0.000        &        0.423    &        0.703     \\\\\n",
       "\\textbf{Q(\"Sp. Def\"):C(Generation)[T.2]} &      -0.2350  &        0.101     &    -2.316  &         0.021        &       -0.434    &       -0.036     \\\\\n",
       "\\textbf{Q(\"Sp. Def\"):C(Generation)[T.3]} &      -0.3067  &        0.093     &    -3.300  &         0.001        &       -0.489    &       -0.124     \\\\\n",
       "\\textbf{Q(\"Sp. Def\"):C(Generation)[T.4]} &      -0.3790  &        0.105     &    -3.600  &         0.000        &       -0.586    &       -0.172     \\\\\n",
       "\\textbf{Q(\"Sp. Def\"):C(Generation)[T.5]} &      -0.0484  &        0.108     &    -0.447  &         0.655        &       -0.261    &        0.164     \\\\\n",
       "\\textbf{Q(\"Sp. Def\"):C(Generation)[T.6]} &      -0.3083  &        0.112     &    -2.756  &         0.006        &       -0.528    &       -0.089     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 337.229 & \\textbf{  Durbin-Watson:     } &    1.505  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } & 2871.522  \\\\\n",
       "\\textbf{Skew:}          &   1.684 & \\textbf{  Prob(JB):          } &     0.00  \\\\\n",
       "\\textbf{Kurtosis:}      &  11.649 & \\textbf{  Cond. No.          } & 1.40e+03  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The condition number is large, 1.4e+03. This might indicate that there are \\newline\n",
       " strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                     HP   R-squared:                       0.176\n",
       "Model:                            OLS   Adj. R-squared:                  0.164\n",
       "Method:                 Least Squares   F-statistic:                     15.27\n",
       "Date:                Fri, 15 Nov 2024   Prob (F-statistic):           3.50e-27\n",
       "Time:                        01:54:12   Log-Likelihood:                -3649.4\n",
       "No. Observations:                 800   AIC:                             7323.\n",
       "Df Residuals:                     788   BIC:                             7379.\n",
       "Df Model:                          11                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "===================================================================================================\n",
       "                                      coef    std err          t      P>|t|      [0.025      0.975]\n",
       "---------------------------------------------------------------------------------------------------\n",
       "Intercept                          26.8971      5.246      5.127      0.000      16.599      37.195\n",
       "C(Generation)[T.2]                 20.0449      7.821      2.563      0.011       4.692      35.398\n",
       "C(Generation)[T.3]                 21.3662      6.998      3.053      0.002       7.629      35.103\n",
       "C(Generation)[T.4]                 31.9575      8.235      3.881      0.000      15.793      48.122\n",
       "C(Generation)[T.5]                  9.4926      7.883      1.204      0.229      -5.982      24.968\n",
       "C(Generation)[T.6]                 22.2693      8.709      2.557      0.011       5.173      39.366\n",
       "Q(\"Sp. Def\")                        0.5634      0.071      7.906      0.000       0.423       0.703\n",
       "Q(\"Sp. Def\"):C(Generation)[T.2]    -0.2350      0.101     -2.316      0.021      -0.434      -0.036\n",
       "Q(\"Sp. Def\"):C(Generation)[T.3]    -0.3067      0.093     -3.300      0.001      -0.489      -0.124\n",
       "Q(\"Sp. Def\"):C(Generation)[T.4]    -0.3790      0.105     -3.600      0.000      -0.586      -0.172\n",
       "Q(\"Sp. Def\"):C(Generation)[T.5]    -0.0484      0.108     -0.447      0.655      -0.261       0.164\n",
       "Q(\"Sp. Def\"):C(Generation)[T.6]    -0.3083      0.112     -2.756      0.006      -0.528      -0.089\n",
       "==============================================================================\n",
       "Omnibus:                      337.229   Durbin-Watson:                   1.505\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2871.522\n",
       "Skew:                           1.684   Prob(JB):                         0.00\n",
       "Kurtosis:                      11.649   Cond. No.                     1.40e+03\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.4e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "\n",
    "model1_spec = smf.ols(formula='HP ~ Q(\"Sp. Def\") + C(Generation)', data=pokeaman)\n",
    "model2_spec = smf.ols(formula='HP ~ Q(\"Sp. Def\") + C(Generation) + Q(\"Sp. Def\"):C(Generation)', data=pokeaman)\n",
    "model2_spec = smf.ols(formula='HP ~ Q(\"Sp. Def\") * C(Generation)', data=pokeaman)\n",
    "\n",
    "model2_fit = model2_spec.fit()\n",
    "model2_fit.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f723964",
   "metadata": {},
   "source": [
    "P-Values from hypothesis testing for coefficient estimates and $R^2$ are distinct, but complementary. They address different aspects of the model.\n",
    "\n",
    "P-values focus on assessing the evidence against the null hypothesis that a specific predictor variable has no linear relationship with the outcome variable, holding all other predictor variables constant. \n",
    "\n",
    "The focus of $R^2$ is to evaluate the overall goodness of the fit of the model, specifically quantifying the proportion of variance in the outcome variable that is explained all the predictor variables included in the model. \n",
    "\n",
    "Statistically significant coefficients  indicate a real relationship between individual predictors and outcome even if the overall $R^2$  of the model of the model is relatively low. \n",
    "If this occurs, one explanation could be the predictors have small individual effects but the effects are reliable and consistent across samples. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc097232",
   "metadata": {},
   "source": [
    "# Post-Lecture "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3e3931",
   "metadata": {},
   "source": [
    "## Question 5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7a6c82aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#</th>\n",
       "      <th>Name</th>\n",
       "      <th>Type 1</th>\n",
       "      <th>Type 2</th>\n",
       "      <th>HP</th>\n",
       "      <th>Attack</th>\n",
       "      <th>Defense</th>\n",
       "      <th>Sp. Atk</th>\n",
       "      <th>Sp. Def</th>\n",
       "      <th>Speed</th>\n",
       "      <th>Generation</th>\n",
       "      <th>Legendary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>338</td>\n",
       "      <td>Solrock</td>\n",
       "      <td>Rock</td>\n",
       "      <td>Psychic</td>\n",
       "      <td>70</td>\n",
       "      <td>95</td>\n",
       "      <td>85</td>\n",
       "      <td>55</td>\n",
       "      <td>65</td>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>Charizard</td>\n",
       "      <td>Fire</td>\n",
       "      <td>Flying</td>\n",
       "      <td>78</td>\n",
       "      <td>84</td>\n",
       "      <td>78</td>\n",
       "      <td>109</td>\n",
       "      <td>85</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>224</td>\n",
       "      <td>Octillery</td>\n",
       "      <td>Water</td>\n",
       "      <td>None</td>\n",
       "      <td>75</td>\n",
       "      <td>105</td>\n",
       "      <td>75</td>\n",
       "      <td>105</td>\n",
       "      <td>75</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661</th>\n",
       "      <td>600</td>\n",
       "      <td>Klang</td>\n",
       "      <td>Steel</td>\n",
       "      <td>None</td>\n",
       "      <td>60</td>\n",
       "      <td>80</td>\n",
       "      <td>95</td>\n",
       "      <td>70</td>\n",
       "      <td>85</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>265</td>\n",
       "      <td>Wurmple</td>\n",
       "      <td>Bug</td>\n",
       "      <td>None</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>35</td>\n",
       "      <td>20</td>\n",
       "      <td>30</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>471</td>\n",
       "      <td>Glaceon</td>\n",
       "      <td>Ice</td>\n",
       "      <td>None</td>\n",
       "      <td>65</td>\n",
       "      <td>60</td>\n",
       "      <td>110</td>\n",
       "      <td>130</td>\n",
       "      <td>95</td>\n",
       "      <td>65</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>225</td>\n",
       "      <td>Delibird</td>\n",
       "      <td>Ice</td>\n",
       "      <td>Flying</td>\n",
       "      <td>45</td>\n",
       "      <td>55</td>\n",
       "      <td>45</td>\n",
       "      <td>65</td>\n",
       "      <td>45</td>\n",
       "      <td>75</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>720</td>\n",
       "      <td>HoopaHoopa Confined</td>\n",
       "      <td>Psychic</td>\n",
       "      <td>Ghost</td>\n",
       "      <td>80</td>\n",
       "      <td>110</td>\n",
       "      <td>60</td>\n",
       "      <td>150</td>\n",
       "      <td>130</td>\n",
       "      <td>70</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>109</td>\n",
       "      <td>Koffing</td>\n",
       "      <td>Poison</td>\n",
       "      <td>None</td>\n",
       "      <td>40</td>\n",
       "      <td>65</td>\n",
       "      <td>95</td>\n",
       "      <td>60</td>\n",
       "      <td>45</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>373</td>\n",
       "      <td>SalamenceMega Salamence</td>\n",
       "      <td>Dragon</td>\n",
       "      <td>Flying</td>\n",
       "      <td>95</td>\n",
       "      <td>145</td>\n",
       "      <td>130</td>\n",
       "      <td>120</td>\n",
       "      <td>90</td>\n",
       "      <td>120</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       #                     Name   Type 1   Type 2  HP  Attack  Defense  \\\n",
       "370  338                  Solrock     Rock  Psychic  70      95       85   \n",
       "6      6                Charizard     Fire   Flying  78      84       78   \n",
       "242  224                Octillery    Water     None  75     105       75   \n",
       "661  600                    Klang    Steel     None  60      80       95   \n",
       "288  265                  Wurmple      Bug     None  45      45       35   \n",
       "..   ...                      ...      ...      ...  ..     ...      ...   \n",
       "522  471                  Glaceon      Ice     None  65      60      110   \n",
       "243  225                 Delibird      Ice   Flying  45      55       45   \n",
       "797  720      HoopaHoopa Confined  Psychic    Ghost  80     110       60   \n",
       "117  109                  Koffing   Poison     None  40      65       95   \n",
       "409  373  SalamenceMega Salamence   Dragon   Flying  95     145      130   \n",
       "\n",
       "     Sp. Atk  Sp. Def  Speed  Generation  Legendary  \n",
       "370       55       65     70           3      False  \n",
       "6        109       85    100           1      False  \n",
       "242      105       75     45           2      False  \n",
       "661       70       85     50           5      False  \n",
       "288       20       30     20           3      False  \n",
       "..       ...      ...    ...         ...        ...  \n",
       "522      130       95     65           4      False  \n",
       "243       65       45     75           2      False  \n",
       "797      150      130     70           6       True  \n",
       "117       60       45     35           1      False  \n",
       "409      120       90    120           3      False  \n",
       "\n",
       "[400 rows x 12 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np # Imported for mathemtical operations\n",
    "from sklearn.model_selection import train_test_split # Imported from sklearn.model_selection to split data into training and testing sets\n",
    "\n",
    "fifty_fifty_split_size = int(pokeaman.shape[0]*0.5) # pokeaman.shape[0] gives the number of rows in the pokeaman dataset. Multiplying by 0.5 and converting to an integer sets the size for a 50/50 split\n",
    "\n",
    "# Replace \"NaN\" (in the \"Type 2\" column with \"None\")\n",
    "pokeaman.fillna('None', inplace=True) # Any missing values in Type 2 column (or elsewhere) are replaced with None\n",
    "\n",
    "np.random.seed(130) # Ensures reproducibility by fixing the random state\n",
    "pokeaman_train,pokeaman_test = train_test_split(pokeaman, train_size=fifty_fifty_split_size) # The train_test_split function splits pokeaman into training (pokeaman_train) and testing (pokeaman_test) sets, with train_size set to half of the data\n",
    "pokeaman_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9fec3ba9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>HP</td>        <th>  R-squared:         </th> <td>   0.148</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.143</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   34.40</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 15 Nov 2024</td> <th>  Prob (F-statistic):</th> <td>1.66e-14</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>01:54:12</td>     <th>  Log-Likelihood:    </th> <td> -1832.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   400</td>      <th>  AIC:               </th> <td>   3671.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   397</td>      <th>  BIC:               </th> <td>   3683.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>   42.5882</td> <td>    3.580</td> <td>   11.897</td> <td> 0.000</td> <td>   35.551</td> <td>   49.626</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack</th>    <td>    0.2472</td> <td>    0.041</td> <td>    6.051</td> <td> 0.000</td> <td>    0.167</td> <td>    0.327</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense</th>   <td>    0.1001</td> <td>    0.045</td> <td>    2.201</td> <td> 0.028</td> <td>    0.011</td> <td>    0.190</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>284.299</td> <th>  Durbin-Watson:     </th> <td>   2.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>5870.841</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 2.720</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>20.963</td>  <th>  Cond. No.          </th> <td>    343.</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &        HP        & \\textbf{  R-squared:         } &     0.148   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.143   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     34.40   \\\\\n",
       "\\textbf{Date:}             & Fri, 15 Nov 2024 & \\textbf{  Prob (F-statistic):} &  1.66e-14   \\\\\n",
       "\\textbf{Time:}             &     01:54:12     & \\textbf{  Log-Likelihood:    } &   -1832.6   \\\\\n",
       "\\textbf{No. Observations:} &         400      & \\textbf{  AIC:               } &     3671.   \\\\\n",
       "\\textbf{Df Residuals:}     &         397      & \\textbf{  BIC:               } &     3683.   \\\\\n",
       "\\textbf{Df Model:}         &           2      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                   & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept} &      42.5882  &        3.580     &    11.897  &         0.000        &       35.551    &       49.626     \\\\\n",
       "\\textbf{Attack}    &       0.2472  &        0.041     &     6.051  &         0.000        &        0.167    &        0.327     \\\\\n",
       "\\textbf{Defense}   &       0.1001  &        0.045     &     2.201  &         0.028        &        0.011    &        0.190     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 284.299 & \\textbf{  Durbin-Watson:     } &    2.006  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } & 5870.841  \\\\\n",
       "\\textbf{Skew:}          &   2.720 & \\textbf{  Prob(JB):          } &     0.00  \\\\\n",
       "\\textbf{Kurtosis:}      &  20.963 & \\textbf{  Cond. No.          } &     343.  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                     HP   R-squared:                       0.148\n",
       "Model:                            OLS   Adj. R-squared:                  0.143\n",
       "Method:                 Least Squares   F-statistic:                     34.40\n",
       "Date:                Fri, 15 Nov 2024   Prob (F-statistic):           1.66e-14\n",
       "Time:                        01:54:12   Log-Likelihood:                -1832.6\n",
       "No. Observations:                 400   AIC:                             3671.\n",
       "Df Residuals:                     397   BIC:                             3683.\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept     42.5882      3.580     11.897      0.000      35.551      49.626\n",
       "Attack         0.2472      0.041      6.051      0.000       0.167       0.327\n",
       "Defense        0.1001      0.045      2.201      0.028       0.011       0.190\n",
       "==============================================================================\n",
       "Omnibus:                      284.299   Durbin-Watson:                   2.006\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             5870.841\n",
       "Skew:                           2.720   Prob(JB):                         0.00\n",
       "Kurtosis:                      20.963   Cond. No.                         343.\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_spec3 = smf.ols(formula='HP ~ Attack + Defense', \n",
    "                      data=pokeaman_train) # Linear regression model created to product the HP column based on Attack and Defense\n",
    "model3_fit = model_spec3.fit() # Stores the fitted model \n",
    "model3_fit.summary() # Provides a detailed summary of the model's performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2f159098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'In sample' R-squared:     0.14771558304519894\n",
      "'Out of sample' R-squared: 0.21208501873920738\n"
     ]
    }
   ],
   "source": [
    "yhat_model3 = model3_fit.predict(pokeaman_test) # Contains predictions for the HP values on the test data \n",
    "y = pokeaman_test.HP # Stores the actual HP values from the test data\n",
    "print(\"'In sample' R-squared:    \", model3_fit.rsquared) # Prints the in-sample R^2 value, which represents how well the model fits the training data\n",
    "print(\"'Out of sample' R-squared:\", np.corrcoef(y,yhat_model3)[0,1]**2) # Prints the out-of-sample R^2 value which is based on the correlation of actual vs. predicted values on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e0ae0575",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>HP</td>        <th>  R-squared:         </th> <td>   0.467</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.369</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   4.764</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 15 Nov 2024</td> <th>  Prob (F-statistic):</th> <td>4.23e-21</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>01:54:13</td>     <th>  Log-Likelihood:    </th> <td> -1738.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   400</td>      <th>  AIC:               </th> <td>   3603.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   337</td>      <th>  BIC:               </th> <td>   3855.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    62</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                                  <td></td>                                    <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                                                        <td>  521.5715</td> <td>  130.273</td> <td>    4.004</td> <td> 0.000</td> <td>  265.322</td> <td>  777.821</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Legendary[T.True]</th>                                                <td>   -6.1179</td> <td>    2.846</td> <td>   -2.150</td> <td> 0.032</td> <td>  -11.716</td> <td>   -0.520</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack</th>                                                           <td>   -8.1938</td> <td>    2.329</td> <td>   -3.518</td> <td> 0.000</td> <td>  -12.775</td> <td>   -3.612</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Legendary[T.True]</th>                                         <td>-1224.9610</td> <td>  545.105</td> <td>   -2.247</td> <td> 0.025</td> <td>-2297.199</td> <td> -152.723</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense</th>                                                          <td>   -6.1989</td> <td>    2.174</td> <td>   -2.851</td> <td> 0.005</td> <td>  -10.475</td> <td>   -1.923</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Legendary[T.True]</th>                                        <td> -102.4030</td> <td>   96.565</td> <td>   -1.060</td> <td> 0.290</td> <td> -292.350</td> <td>   87.544</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense</th>                                                   <td>    0.0985</td> <td>    0.033</td> <td>    2.982</td> <td> 0.003</td> <td>    0.034</td> <td>    0.164</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Legendary[T.True]</th>                                 <td>   14.6361</td> <td>    6.267</td> <td>    2.336</td> <td> 0.020</td> <td>    2.310</td> <td>   26.963</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Speed</th>                                                            <td>   -7.2261</td> <td>    2.178</td> <td>   -3.318</td> <td> 0.001</td> <td>  -11.511</td> <td>   -2.942</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Speed:Legendary[T.True]</th>                                          <td>  704.8798</td> <td>  337.855</td> <td>    2.086</td> <td> 0.038</td> <td>   40.309</td> <td> 1369.450</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Speed</th>                                                     <td>    0.1264</td> <td>    0.038</td> <td>    3.351</td> <td> 0.001</td> <td>    0.052</td> <td>    0.201</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Speed:Legendary[T.True]</th>                                   <td>    5.8648</td> <td>    2.692</td> <td>    2.179</td> <td> 0.030</td> <td>    0.570</td> <td>   11.160</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Speed</th>                                                    <td>    0.1026</td> <td>    0.039</td> <td>    2.634</td> <td> 0.009</td> <td>    0.026</td> <td>    0.179</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Speed:Legendary[T.True]</th>                                  <td>   -6.9266</td> <td>    3.465</td> <td>   -1.999</td> <td> 0.046</td> <td>  -13.742</td> <td>   -0.111</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Speed</th>                                             <td>   -0.0016</td> <td>    0.001</td> <td>   -2.837</td> <td> 0.005</td> <td>   -0.003</td> <td>   -0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Speed:Legendary[T.True]</th>                           <td>   -0.0743</td> <td>    0.030</td> <td>   -2.477</td> <td> 0.014</td> <td>   -0.133</td> <td>   -0.015</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Def\")</th>                                                     <td>   -5.3982</td> <td>    1.938</td> <td>   -2.785</td> <td> 0.006</td> <td>   -9.211</td> <td>   -1.586</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Legendary[T.True]:Q(\"Sp. Def\")</th>                                   <td> -282.2496</td> <td>  126.835</td> <td>   -2.225</td> <td> 0.027</td> <td> -531.738</td> <td>  -32.761</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Q(\"Sp. Def\")</th>                                              <td>    0.1094</td> <td>    0.034</td> <td>    3.233</td> <td> 0.001</td> <td>    0.043</td> <td>    0.176</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Legendary[T.True]:Q(\"Sp. Def\")</th>                            <td>   12.6503</td> <td>    5.851</td> <td>    2.162</td> <td> 0.031</td> <td>    1.141</td> <td>   24.160</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Q(\"Sp. Def\")</th>                                             <td>    0.0628</td> <td>    0.028</td> <td>    2.247</td> <td> 0.025</td> <td>    0.008</td> <td>    0.118</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Legendary[T.True]:Q(\"Sp. Def\")</th>                           <td>    3.3949</td> <td>    1.783</td> <td>    1.904</td> <td> 0.058</td> <td>   -0.112</td> <td>    6.902</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Q(\"Sp. Def\")</th>                                      <td>   -0.0012</td> <td>    0.000</td> <td>   -2.730</td> <td> 0.007</td> <td>   -0.002</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Legendary[T.True]:Q(\"Sp. Def\")</th>                    <td>   -0.1456</td> <td>    0.065</td> <td>   -2.253</td> <td> 0.025</td> <td>   -0.273</td> <td>   -0.018</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Speed:Q(\"Sp. Def\")</th>                                               <td>    0.0624</td> <td>    0.031</td> <td>    2.027</td> <td> 0.043</td> <td>    0.002</td> <td>    0.123</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Speed:Legendary[T.True]:Q(\"Sp. Def\")</th>                             <td>   -3.2219</td> <td>    1.983</td> <td>   -1.625</td> <td> 0.105</td> <td>   -7.122</td> <td>    0.678</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Speed:Q(\"Sp. Def\")</th>                                        <td>   -0.0014</td> <td>    0.001</td> <td>   -2.732</td> <td> 0.007</td> <td>   -0.002</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Speed:Legendary[T.True]:Q(\"Sp. Def\")</th>                      <td>   -0.0695</td> <td>    0.033</td> <td>   -2.100</td> <td> 0.036</td> <td>   -0.135</td> <td>   -0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Speed:Q(\"Sp. Def\")</th>                                       <td>   -0.0008</td> <td>    0.000</td> <td>   -1.743</td> <td> 0.082</td> <td>   -0.002</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Speed:Legendary[T.True]:Q(\"Sp. Def\")</th>                     <td>    0.0334</td> <td>    0.021</td> <td>    1.569</td> <td> 0.117</td> <td>   -0.008</td> <td>    0.075</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Speed:Q(\"Sp. Def\")</th>                                <td> 1.629e-05</td> <td> 6.92e-06</td> <td>    2.355</td> <td> 0.019</td> <td> 2.68e-06</td> <td> 2.99e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Speed:Legendary[T.True]:Q(\"Sp. Def\")</th>              <td>    0.0008</td> <td>    0.000</td> <td>    2.433</td> <td> 0.015</td> <td>    0.000</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Atk\")</th>                                                     <td>   -8.3636</td> <td>    2.346</td> <td>   -3.565</td> <td> 0.000</td> <td>  -12.978</td> <td>   -3.749</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Legendary[T.True]:Q(\"Sp. Atk\")</th>                                   <td>  850.5436</td> <td>  385.064</td> <td>    2.209</td> <td> 0.028</td> <td>   93.112</td> <td> 1607.975</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Q(\"Sp. Atk\")</th>                                              <td>    0.1388</td> <td>    0.040</td> <td>    3.500</td> <td> 0.001</td> <td>    0.061</td> <td>    0.217</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Legendary[T.True]:Q(\"Sp. Atk\")</th>                            <td>    2.1809</td> <td>    1.136</td> <td>    1.920</td> <td> 0.056</td> <td>   -0.054</td> <td>    4.416</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Q(\"Sp. Atk\")</th>                                             <td>    0.0831</td> <td>    0.038</td> <td>    2.162</td> <td> 0.031</td> <td>    0.007</td> <td>    0.159</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Legendary[T.True]:Q(\"Sp. Atk\")</th>                           <td>   -7.3121</td> <td>    3.376</td> <td>   -2.166</td> <td> 0.031</td> <td>  -13.953</td> <td>   -0.671</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Q(\"Sp. Atk\")</th>                                      <td>   -0.0014</td> <td>    0.001</td> <td>   -2.480</td> <td> 0.014</td> <td>   -0.003</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Legendary[T.True]:Q(\"Sp. Atk\")</th>                    <td>   -0.0434</td> <td>    0.022</td> <td>   -2.010</td> <td> 0.045</td> <td>   -0.086</td> <td>   -0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Speed:Q(\"Sp. Atk\")</th>                                               <td>    0.1011</td> <td>    0.035</td> <td>    2.872</td> <td> 0.004</td> <td>    0.032</td> <td>    0.170</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Speed:Legendary[T.True]:Q(\"Sp. Atk\")</th>                             <td>  -12.6343</td> <td>    5.613</td> <td>   -2.251</td> <td> 0.025</td> <td>  -23.674</td> <td>   -1.594</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Speed:Q(\"Sp. Atk\")</th>                                        <td>   -0.0018</td> <td>    0.001</td> <td>   -3.102</td> <td> 0.002</td> <td>   -0.003</td> <td>   -0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Speed:Legendary[T.True]:Q(\"Sp. Atk\")</th>                      <td>    0.0151</td> <td>    0.009</td> <td>    1.609</td> <td> 0.109</td> <td>   -0.003</td> <td>    0.034</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Speed:Q(\"Sp. Atk\")</th>                                       <td>   -0.0012</td> <td>    0.001</td> <td>   -1.860</td> <td> 0.064</td> <td>   -0.002</td> <td> 6.62e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Speed:Legendary[T.True]:Q(\"Sp. Atk\")</th>                     <td>    0.1210</td> <td>    0.054</td> <td>    2.260</td> <td> 0.024</td> <td>    0.016</td> <td>    0.226</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Speed:Q(\"Sp. Atk\")</th>                                <td> 2.125e-05</td> <td>  9.1e-06</td> <td>    2.334</td> <td> 0.020</td> <td> 3.34e-06</td> <td> 3.92e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Speed:Legendary[T.True]:Q(\"Sp. Atk\")</th>              <td> 6.438e-06</td> <td> 7.69e-05</td> <td>    0.084</td> <td> 0.933</td> <td>   -0.000</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>                                        <td>    0.1265</td> <td>    0.033</td> <td>    3.821</td> <td> 0.000</td> <td>    0.061</td> <td>    0.192</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>                      <td>   -5.0544</td> <td>    2.506</td> <td>   -2.017</td> <td> 0.044</td> <td>   -9.983</td> <td>   -0.126</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>                                 <td>   -0.0021</td> <td>    0.001</td> <td>   -3.606</td> <td> 0.000</td> <td>   -0.003</td> <td>   -0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>               <td>   -0.0346</td> <td>    0.017</td> <td>   -1.992</td> <td> 0.047</td> <td>   -0.069</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>                                <td>   -0.0012</td> <td>    0.000</td> <td>   -2.406</td> <td> 0.017</td> <td>   -0.002</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>              <td>    0.0446</td> <td>    0.025</td> <td>    1.794</td> <td> 0.074</td> <td>   -0.004</td> <td>    0.093</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>                         <td> 1.973e-05</td> <td> 7.28e-06</td> <td>    2.710</td> <td> 0.007</td> <td> 5.41e-06</td> <td>  3.4e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>       <td>    0.0005</td> <td>    0.000</td> <td>    1.957</td> <td> 0.051</td> <td>-2.56e-06</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>                                  <td>   -0.0013</td> <td>    0.000</td> <td>   -2.740</td> <td> 0.006</td> <td>   -0.002</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Speed:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>                <td>    0.0841</td> <td>    0.040</td> <td>    2.125</td> <td> 0.034</td> <td>    0.006</td> <td>    0.162</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>                           <td> 2.379e-05</td> <td> 7.85e-06</td> <td>    3.030</td> <td> 0.003</td> <td> 8.34e-06</td> <td> 3.92e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Speed:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>         <td> 2.864e-05</td> <td> 7.73e-05</td> <td>    0.370</td> <td> 0.711</td> <td>   -0.000</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>                          <td> 1.284e-05</td> <td> 7.46e-06</td> <td>    1.721</td> <td> 0.086</td> <td>-1.83e-06</td> <td> 2.75e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Speed:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>        <td>   -0.0008</td> <td>    0.000</td> <td>   -2.085</td> <td> 0.038</td> <td>   -0.002</td> <td>-4.68e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>                   <td> -2.53e-07</td> <td>  1.1e-07</td> <td>   -2.292</td> <td> 0.023</td> <td> -4.7e-07</td> <td>-3.59e-08</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Speed:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th> <td>-1.425e-06</td> <td> 1.14e-06</td> <td>   -1.249</td> <td> 0.212</td> <td>-3.67e-06</td> <td> 8.19e-07</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>214.307</td> <th>  Durbin-Watson:     </th> <td>   1.992</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>2354.664</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 2.026</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>14.174</td>  <th>  Cond. No.          </th> <td>1.20e+16</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.2e+16. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}                                                   &        HP        & \\textbf{  R-squared:         } &     0.467   \\\\\n",
       "\\textbf{Model:}                                                           &       OLS        & \\textbf{  Adj. R-squared:    } &     0.369   \\\\\n",
       "\\textbf{Method:}                                                          &  Least Squares   & \\textbf{  F-statistic:       } &     4.764   \\\\\n",
       "\\textbf{Date:}                                                            & Fri, 15 Nov 2024 & \\textbf{  Prob (F-statistic):} &  4.23e-21   \\\\\n",
       "\\textbf{Time:}                                                            &     01:54:13     & \\textbf{  Log-Likelihood:    } &   -1738.6   \\\\\n",
       "\\textbf{No. Observations:}                                                &         400      & \\textbf{  AIC:               } &     3603.   \\\\\n",
       "\\textbf{Df Residuals:}                                                    &         337      & \\textbf{  BIC:               } &     3855.   \\\\\n",
       "\\textbf{Df Model:}                                                        &          62      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}                                                 &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                                                                          & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept}                                                        &     521.5715  &      130.273     &     4.004  &         0.000        &      265.322    &      777.821     \\\\\n",
       "\\textbf{Legendary[T.True]}                                                &      -6.1179  &        2.846     &    -2.150  &         0.032        &      -11.716    &       -0.520     \\\\\n",
       "\\textbf{Attack}                                                           &      -8.1938  &        2.329     &    -3.518  &         0.000        &      -12.775    &       -3.612     \\\\\n",
       "\\textbf{Attack:Legendary[T.True]}                                         &   -1224.9610  &      545.105     &    -2.247  &         0.025        &    -2297.199    &     -152.723     \\\\\n",
       "\\textbf{Defense}                                                          &      -6.1989  &        2.174     &    -2.851  &         0.005        &      -10.475    &       -1.923     \\\\\n",
       "\\textbf{Defense:Legendary[T.True]}                                        &    -102.4030  &       96.565     &    -1.060  &         0.290        &     -292.350    &       87.544     \\\\\n",
       "\\textbf{Attack:Defense}                                                   &       0.0985  &        0.033     &     2.982  &         0.003        &        0.034    &        0.164     \\\\\n",
       "\\textbf{Attack:Defense:Legendary[T.True]}                                 &      14.6361  &        6.267     &     2.336  &         0.020        &        2.310    &       26.963     \\\\\n",
       "\\textbf{Speed}                                                            &      -7.2261  &        2.178     &    -3.318  &         0.001        &      -11.511    &       -2.942     \\\\\n",
       "\\textbf{Speed:Legendary[T.True]}                                          &     704.8798  &      337.855     &     2.086  &         0.038        &       40.309    &     1369.450     \\\\\n",
       "\\textbf{Attack:Speed}                                                     &       0.1264  &        0.038     &     3.351  &         0.001        &        0.052    &        0.201     \\\\\n",
       "\\textbf{Attack:Speed:Legendary[T.True]}                                   &       5.8648  &        2.692     &     2.179  &         0.030        &        0.570    &       11.160     \\\\\n",
       "\\textbf{Defense:Speed}                                                    &       0.1026  &        0.039     &     2.634  &         0.009        &        0.026    &        0.179     \\\\\n",
       "\\textbf{Defense:Speed:Legendary[T.True]}                                  &      -6.9266  &        3.465     &    -1.999  &         0.046        &      -13.742    &       -0.111     \\\\\n",
       "\\textbf{Attack:Defense:Speed}                                             &      -0.0016  &        0.001     &    -2.837  &         0.005        &       -0.003    &       -0.001     \\\\\n",
       "\\textbf{Attack:Defense:Speed:Legendary[T.True]}                           &      -0.0743  &        0.030     &    -2.477  &         0.014        &       -0.133    &       -0.015     \\\\\n",
       "\\textbf{Q(\"Sp. Def\")}                                                     &      -5.3982  &        1.938     &    -2.785  &         0.006        &       -9.211    &       -1.586     \\\\\n",
       "\\textbf{Legendary[T.True]:Q(\"Sp. Def\")}                                   &    -282.2496  &      126.835     &    -2.225  &         0.027        &     -531.738    &      -32.761     \\\\\n",
       "\\textbf{Attack:Q(\"Sp. Def\")}                                              &       0.1094  &        0.034     &     3.233  &         0.001        &        0.043    &        0.176     \\\\\n",
       "\\textbf{Attack:Legendary[T.True]:Q(\"Sp. Def\")}                            &      12.6503  &        5.851     &     2.162  &         0.031        &        1.141    &       24.160     \\\\\n",
       "\\textbf{Defense:Q(\"Sp. Def\")}                                             &       0.0628  &        0.028     &     2.247  &         0.025        &        0.008    &        0.118     \\\\\n",
       "\\textbf{Defense:Legendary[T.True]:Q(\"Sp. Def\")}                           &       3.3949  &        1.783     &     1.904  &         0.058        &       -0.112    &        6.902     \\\\\n",
       "\\textbf{Attack:Defense:Q(\"Sp. Def\")}                                      &      -0.0012  &        0.000     &    -2.730  &         0.007        &       -0.002    &       -0.000     \\\\\n",
       "\\textbf{Attack:Defense:Legendary[T.True]:Q(\"Sp. Def\")}                    &      -0.1456  &        0.065     &    -2.253  &         0.025        &       -0.273    &       -0.018     \\\\\n",
       "\\textbf{Speed:Q(\"Sp. Def\")}                                               &       0.0624  &        0.031     &     2.027  &         0.043        &        0.002    &        0.123     \\\\\n",
       "\\textbf{Speed:Legendary[T.True]:Q(\"Sp. Def\")}                             &      -3.2219  &        1.983     &    -1.625  &         0.105        &       -7.122    &        0.678     \\\\\n",
       "\\textbf{Attack:Speed:Q(\"Sp. Def\")}                                        &      -0.0014  &        0.001     &    -2.732  &         0.007        &       -0.002    &       -0.000     \\\\\n",
       "\\textbf{Attack:Speed:Legendary[T.True]:Q(\"Sp. Def\")}                      &      -0.0695  &        0.033     &    -2.100  &         0.036        &       -0.135    &       -0.004     \\\\\n",
       "\\textbf{Defense:Speed:Q(\"Sp. Def\")}                                       &      -0.0008  &        0.000     &    -1.743  &         0.082        &       -0.002    &        0.000     \\\\\n",
       "\\textbf{Defense:Speed:Legendary[T.True]:Q(\"Sp. Def\")}                     &       0.0334  &        0.021     &     1.569  &         0.117        &       -0.008    &        0.075     \\\\\n",
       "\\textbf{Attack:Defense:Speed:Q(\"Sp. Def\")}                                &    1.629e-05  &     6.92e-06     &     2.355  &         0.019        &     2.68e-06    &     2.99e-05     \\\\\n",
       "\\textbf{Attack:Defense:Speed:Legendary[T.True]:Q(\"Sp. Def\")}              &       0.0008  &        0.000     &     2.433  &         0.015        &        0.000    &        0.001     \\\\\n",
       "\\textbf{Q(\"Sp. Atk\")}                                                     &      -8.3636  &        2.346     &    -3.565  &         0.000        &      -12.978    &       -3.749     \\\\\n",
       "\\textbf{Legendary[T.True]:Q(\"Sp. Atk\")}                                   &     850.5436  &      385.064     &     2.209  &         0.028        &       93.112    &     1607.975     \\\\\n",
       "\\textbf{Attack:Q(\"Sp. Atk\")}                                              &       0.1388  &        0.040     &     3.500  &         0.001        &        0.061    &        0.217     \\\\\n",
       "\\textbf{Attack:Legendary[T.True]:Q(\"Sp. Atk\")}                            &       2.1809  &        1.136     &     1.920  &         0.056        &       -0.054    &        4.416     \\\\\n",
       "\\textbf{Defense:Q(\"Sp. Atk\")}                                             &       0.0831  &        0.038     &     2.162  &         0.031        &        0.007    &        0.159     \\\\\n",
       "\\textbf{Defense:Legendary[T.True]:Q(\"Sp. Atk\")}                           &      -7.3121  &        3.376     &    -2.166  &         0.031        &      -13.953    &       -0.671     \\\\\n",
       "\\textbf{Attack:Defense:Q(\"Sp. Atk\")}                                      &      -0.0014  &        0.001     &    -2.480  &         0.014        &       -0.003    &       -0.000     \\\\\n",
       "\\textbf{Attack:Defense:Legendary[T.True]:Q(\"Sp. Atk\")}                    &      -0.0434  &        0.022     &    -2.010  &         0.045        &       -0.086    &       -0.001     \\\\\n",
       "\\textbf{Speed:Q(\"Sp. Atk\")}                                               &       0.1011  &        0.035     &     2.872  &         0.004        &        0.032    &        0.170     \\\\\n",
       "\\textbf{Speed:Legendary[T.True]:Q(\"Sp. Atk\")}                             &     -12.6343  &        5.613     &    -2.251  &         0.025        &      -23.674    &       -1.594     \\\\\n",
       "\\textbf{Attack:Speed:Q(\"Sp. Atk\")}                                        &      -0.0018  &        0.001     &    -3.102  &         0.002        &       -0.003    &       -0.001     \\\\\n",
       "\\textbf{Attack:Speed:Legendary[T.True]:Q(\"Sp. Atk\")}                      &       0.0151  &        0.009     &     1.609  &         0.109        &       -0.003    &        0.034     \\\\\n",
       "\\textbf{Defense:Speed:Q(\"Sp. Atk\")}                                       &      -0.0012  &        0.001     &    -1.860  &         0.064        &       -0.002    &     6.62e-05     \\\\\n",
       "\\textbf{Defense:Speed:Legendary[T.True]:Q(\"Sp. Atk\")}                     &       0.1210  &        0.054     &     2.260  &         0.024        &        0.016    &        0.226     \\\\\n",
       "\\textbf{Attack:Defense:Speed:Q(\"Sp. Atk\")}                                &    2.125e-05  &      9.1e-06     &     2.334  &         0.020        &     3.34e-06    &     3.92e-05     \\\\\n",
       "\\textbf{Attack:Defense:Speed:Legendary[T.True]:Q(\"Sp. Atk\")}              &    6.438e-06  &     7.69e-05     &     0.084  &         0.933        &       -0.000    &        0.000     \\\\\n",
       "\\textbf{Q(\"Sp. Def\"):Q(\"Sp. Atk\")}                                        &       0.1265  &        0.033     &     3.821  &         0.000        &        0.061    &        0.192     \\\\\n",
       "\\textbf{Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}                      &      -5.0544  &        2.506     &    -2.017  &         0.044        &       -9.983    &       -0.126     \\\\\n",
       "\\textbf{Attack:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}                                 &      -0.0021  &        0.001     &    -3.606  &         0.000        &       -0.003    &       -0.001     \\\\\n",
       "\\textbf{Attack:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}               &      -0.0346  &        0.017     &    -1.992  &         0.047        &       -0.069    &       -0.000     \\\\\n",
       "\\textbf{Defense:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}                                &      -0.0012  &        0.000     &    -2.406  &         0.017        &       -0.002    &       -0.000     \\\\\n",
       "\\textbf{Defense:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}              &       0.0446  &        0.025     &     1.794  &         0.074        &       -0.004    &        0.093     \\\\\n",
       "\\textbf{Attack:Defense:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}                         &    1.973e-05  &     7.28e-06     &     2.710  &         0.007        &     5.41e-06    &      3.4e-05     \\\\\n",
       "\\textbf{Attack:Defense:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}       &       0.0005  &        0.000     &     1.957  &         0.051        &    -2.56e-06    &        0.001     \\\\\n",
       "\\textbf{Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}                                  &      -0.0013  &        0.000     &    -2.740  &         0.006        &       -0.002    &       -0.000     \\\\\n",
       "\\textbf{Speed:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}                &       0.0841  &        0.040     &     2.125  &         0.034        &        0.006    &        0.162     \\\\\n",
       "\\textbf{Attack:Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}                           &    2.379e-05  &     7.85e-06     &     3.030  &         0.003        &     8.34e-06    &     3.92e-05     \\\\\n",
       "\\textbf{Attack:Speed:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}         &    2.864e-05  &     7.73e-05     &     0.370  &         0.711        &       -0.000    &        0.000     \\\\\n",
       "\\textbf{Defense:Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}                          &    1.284e-05  &     7.46e-06     &     1.721  &         0.086        &    -1.83e-06    &     2.75e-05     \\\\\n",
       "\\textbf{Defense:Speed:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}        &      -0.0008  &        0.000     &    -2.085  &         0.038        &       -0.002    &    -4.68e-05     \\\\\n",
       "\\textbf{Attack:Defense:Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}                   &    -2.53e-07  &      1.1e-07     &    -2.292  &         0.023        &     -4.7e-07    &    -3.59e-08     \\\\\n",
       "\\textbf{Attack:Defense:Speed:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")} &   -1.425e-06  &     1.14e-06     &    -1.249  &         0.212        &    -3.67e-06    &     8.19e-07     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 214.307 & \\textbf{  Durbin-Watson:     } &    1.992  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } & 2354.664  \\\\\n",
       "\\textbf{Skew:}          &   2.026 & \\textbf{  Prob(JB):          } &     0.00  \\\\\n",
       "\\textbf{Kurtosis:}      &  14.174 & \\textbf{  Cond. No.          } & 1.20e+16  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The condition number is large, 1.2e+16. This might indicate that there are \\newline\n",
       " strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                     HP   R-squared:                       0.467\n",
       "Model:                            OLS   Adj. R-squared:                  0.369\n",
       "Method:                 Least Squares   F-statistic:                     4.764\n",
       "Date:                Fri, 15 Nov 2024   Prob (F-statistic):           4.23e-21\n",
       "Time:                        01:54:13   Log-Likelihood:                -1738.6\n",
       "No. Observations:                 400   AIC:                             3603.\n",
       "Df Residuals:                     337   BIC:                             3855.\n",
       "Df Model:                          62                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "====================================================================================================================================\n",
       "                                                                       coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------------------------------------------------------------\n",
       "Intercept                                                          521.5715    130.273      4.004      0.000     265.322     777.821\n",
       "Legendary[T.True]                                                   -6.1179      2.846     -2.150      0.032     -11.716      -0.520\n",
       "Attack                                                              -8.1938      2.329     -3.518      0.000     -12.775      -3.612\n",
       "Attack:Legendary[T.True]                                         -1224.9610    545.105     -2.247      0.025   -2297.199    -152.723\n",
       "Defense                                                             -6.1989      2.174     -2.851      0.005     -10.475      -1.923\n",
       "Defense:Legendary[T.True]                                         -102.4030     96.565     -1.060      0.290    -292.350      87.544\n",
       "Attack:Defense                                                       0.0985      0.033      2.982      0.003       0.034       0.164\n",
       "Attack:Defense:Legendary[T.True]                                    14.6361      6.267      2.336      0.020       2.310      26.963\n",
       "Speed                                                               -7.2261      2.178     -3.318      0.001     -11.511      -2.942\n",
       "Speed:Legendary[T.True]                                            704.8798    337.855      2.086      0.038      40.309    1369.450\n",
       "Attack:Speed                                                         0.1264      0.038      3.351      0.001       0.052       0.201\n",
       "Attack:Speed:Legendary[T.True]                                       5.8648      2.692      2.179      0.030       0.570      11.160\n",
       "Defense:Speed                                                        0.1026      0.039      2.634      0.009       0.026       0.179\n",
       "Defense:Speed:Legendary[T.True]                                     -6.9266      3.465     -1.999      0.046     -13.742      -0.111\n",
       "Attack:Defense:Speed                                                -0.0016      0.001     -2.837      0.005      -0.003      -0.001\n",
       "Attack:Defense:Speed:Legendary[T.True]                              -0.0743      0.030     -2.477      0.014      -0.133      -0.015\n",
       "Q(\"Sp. Def\")                                                        -5.3982      1.938     -2.785      0.006      -9.211      -1.586\n",
       "Legendary[T.True]:Q(\"Sp. Def\")                                    -282.2496    126.835     -2.225      0.027    -531.738     -32.761\n",
       "Attack:Q(\"Sp. Def\")                                                  0.1094      0.034      3.233      0.001       0.043       0.176\n",
       "Attack:Legendary[T.True]:Q(\"Sp. Def\")                               12.6503      5.851      2.162      0.031       1.141      24.160\n",
       "Defense:Q(\"Sp. Def\")                                                 0.0628      0.028      2.247      0.025       0.008       0.118\n",
       "Defense:Legendary[T.True]:Q(\"Sp. Def\")                               3.3949      1.783      1.904      0.058      -0.112       6.902\n",
       "Attack:Defense:Q(\"Sp. Def\")                                         -0.0012      0.000     -2.730      0.007      -0.002      -0.000\n",
       "Attack:Defense:Legendary[T.True]:Q(\"Sp. Def\")                       -0.1456      0.065     -2.253      0.025      -0.273      -0.018\n",
       "Speed:Q(\"Sp. Def\")                                                   0.0624      0.031      2.027      0.043       0.002       0.123\n",
       "Speed:Legendary[T.True]:Q(\"Sp. Def\")                                -3.2219      1.983     -1.625      0.105      -7.122       0.678\n",
       "Attack:Speed:Q(\"Sp. Def\")                                           -0.0014      0.001     -2.732      0.007      -0.002      -0.000\n",
       "Attack:Speed:Legendary[T.True]:Q(\"Sp. Def\")                         -0.0695      0.033     -2.100      0.036      -0.135      -0.004\n",
       "Defense:Speed:Q(\"Sp. Def\")                                          -0.0008      0.000     -1.743      0.082      -0.002       0.000\n",
       "Defense:Speed:Legendary[T.True]:Q(\"Sp. Def\")                         0.0334      0.021      1.569      0.117      -0.008       0.075\n",
       "Attack:Defense:Speed:Q(\"Sp. Def\")                                 1.629e-05   6.92e-06      2.355      0.019    2.68e-06    2.99e-05\n",
       "Attack:Defense:Speed:Legendary[T.True]:Q(\"Sp. Def\")                  0.0008      0.000      2.433      0.015       0.000       0.001\n",
       "Q(\"Sp. Atk\")                                                        -8.3636      2.346     -3.565      0.000     -12.978      -3.749\n",
       "Legendary[T.True]:Q(\"Sp. Atk\")                                     850.5436    385.064      2.209      0.028      93.112    1607.975\n",
       "Attack:Q(\"Sp. Atk\")                                                  0.1388      0.040      3.500      0.001       0.061       0.217\n",
       "Attack:Legendary[T.True]:Q(\"Sp. Atk\")                                2.1809      1.136      1.920      0.056      -0.054       4.416\n",
       "Defense:Q(\"Sp. Atk\")                                                 0.0831      0.038      2.162      0.031       0.007       0.159\n",
       "Defense:Legendary[T.True]:Q(\"Sp. Atk\")                              -7.3121      3.376     -2.166      0.031     -13.953      -0.671\n",
       "Attack:Defense:Q(\"Sp. Atk\")                                         -0.0014      0.001     -2.480      0.014      -0.003      -0.000\n",
       "Attack:Defense:Legendary[T.True]:Q(\"Sp. Atk\")                       -0.0434      0.022     -2.010      0.045      -0.086      -0.001\n",
       "Speed:Q(\"Sp. Atk\")                                                   0.1011      0.035      2.872      0.004       0.032       0.170\n",
       "Speed:Legendary[T.True]:Q(\"Sp. Atk\")                               -12.6343      5.613     -2.251      0.025     -23.674      -1.594\n",
       "Attack:Speed:Q(\"Sp. Atk\")                                           -0.0018      0.001     -3.102      0.002      -0.003      -0.001\n",
       "Attack:Speed:Legendary[T.True]:Q(\"Sp. Atk\")                          0.0151      0.009      1.609      0.109      -0.003       0.034\n",
       "Defense:Speed:Q(\"Sp. Atk\")                                          -0.0012      0.001     -1.860      0.064      -0.002    6.62e-05\n",
       "Defense:Speed:Legendary[T.True]:Q(\"Sp. Atk\")                         0.1210      0.054      2.260      0.024       0.016       0.226\n",
       "Attack:Defense:Speed:Q(\"Sp. Atk\")                                 2.125e-05    9.1e-06      2.334      0.020    3.34e-06    3.92e-05\n",
       "Attack:Defense:Speed:Legendary[T.True]:Q(\"Sp. Atk\")               6.438e-06   7.69e-05      0.084      0.933      -0.000       0.000\n",
       "Q(\"Sp. Def\"):Q(\"Sp. Atk\")                                            0.1265      0.033      3.821      0.000       0.061       0.192\n",
       "Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")                         -5.0544      2.506     -2.017      0.044      -9.983      -0.126\n",
       "Attack:Q(\"Sp. Def\"):Q(\"Sp. Atk\")                                    -0.0021      0.001     -3.606      0.000      -0.003      -0.001\n",
       "Attack:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")                  -0.0346      0.017     -1.992      0.047      -0.069      -0.000\n",
       "Defense:Q(\"Sp. Def\"):Q(\"Sp. Atk\")                                   -0.0012      0.000     -2.406      0.017      -0.002      -0.000\n",
       "Defense:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")                  0.0446      0.025      1.794      0.074      -0.004       0.093\n",
       "Attack:Defense:Q(\"Sp. Def\"):Q(\"Sp. Atk\")                          1.973e-05   7.28e-06      2.710      0.007    5.41e-06     3.4e-05\n",
       "Attack:Defense:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")           0.0005      0.000      1.957      0.051   -2.56e-06       0.001\n",
       "Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")                                     -0.0013      0.000     -2.740      0.006      -0.002      -0.000\n",
       "Speed:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")                    0.0841      0.040      2.125      0.034       0.006       0.162\n",
       "Attack:Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")                            2.379e-05   7.85e-06      3.030      0.003    8.34e-06    3.92e-05\n",
       "Attack:Speed:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")          2.864e-05   7.73e-05      0.370      0.711      -0.000       0.000\n",
       "Defense:Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")                           1.284e-05   7.46e-06      1.721      0.086   -1.83e-06    2.75e-05\n",
       "Defense:Speed:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")           -0.0008      0.000     -2.085      0.038      -0.002   -4.68e-05\n",
       "Attack:Defense:Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")                    -2.53e-07    1.1e-07     -2.292      0.023    -4.7e-07   -3.59e-08\n",
       "Attack:Defense:Speed:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\") -1.425e-06   1.14e-06     -1.249      0.212   -3.67e-06    8.19e-07\n",
       "==============================================================================\n",
       "Omnibus:                      214.307   Durbin-Watson:                   1.992\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2354.664\n",
       "Skew:                           2.026   Prob(JB):                         0.00\n",
       "Kurtosis:                      14.174   Cond. No.                     1.20e+16\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.2e+16. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4_linear_form = 'HP ~ Attack * Defense * Speed * Legendary' # Specifies HP as the dependent variable and includes interactions among Attack, Defense, Spped, and Legendary and considers all pairwise, three-way and four-way interactions between them\n",
    "model4_linear_form += ' * Q(\"Sp. Def\") * Q(\"Sp. Atk\")' # Extends these interactions to include Sp. Def and Sp. Atk, and allows variables with special characters or spaces in their names\n",
    "\n",
    "# DO NOT try adding '* C(Generation) * C(Q(\"Type 1\")) * C(Q(\"Type 2\"))'\n",
    "# That's 6*18*19 = 6*18*19 possible interaction combinations...\n",
    "# ...a huge number that will blow up your computer\n",
    "\n",
    "model4_spec = smf.ols(formula=model4_linear_form, data=pokeaman_train) # Defines an Ordinary Least Squares (OLS) regression model\n",
    "model4_fit = model4_spec.fit() # Fitted model's parameters and diagnostics is stored\n",
    "model4_fit.summary() # Provides a detailed summary of the model's performance (including coefficients, sig. levels, R-squared values) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a5c146c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'In sample' R-squared:     0.46709442115833855\n",
      "'Out of sample' R-squared: 0.002485342598992873\n"
     ]
    }
   ],
   "source": [
    "yhat_model4 = model4_fit.predict(pokeaman_test) # Contains the predicted HP values for the test dataset based on the regression model model4_fit\n",
    "y = pokeaman_test.HP # Extracting true HP values since y has those values from the Pokeaman test dataset, which will be used to compare against predicted values\n",
    "print(\"'In sample' R-squared:    \", model4_fit.rsquared) # Measures how well the model explains the variability of HP within the training data\n",
    "print(\"'Out of sample' R-squared:\", np.corrcoef(y,yhat_model4)[0,1]**2) # How well the model's predictions match the actual HP values in the test data. np.corrcoef(y, yhat_model4)[0, 1] calculates the correlation coefficient between actual and predicted HP values in test data. Squaring it provides out-of-sample R^2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb42542",
   "metadata": {},
   "source": [
    "This code illustrates the process of building more complex regression models, evaluating their peformance on training and test sets, and understanding the trade-offs between model complexity and predictive accuracy. This code emphasizes the importance of out-of-sample testing to make sure that a model is not overfitting to the training data and can generalize new data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10374d1e",
   "metadata": {},
   "source": [
    "## Question 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a50a3790",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>HP</td>        <th>  R-squared:         </th> <td>   0.268</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.265</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   72.79</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 15 Nov 2024</td> <th>  Prob (F-statistic):</th> <td>1.17e-27</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>01:54:13</td>     <th>  Log-Likelihood:    </th> <td> -1776.2</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   400</td>      <th>  AIC:               </th> <td>   3558.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   397</td>      <th>  BIC:               </th> <td>   3570.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "             <td></td>               <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>              <td>   68.1325</td> <td>    1.030</td> <td>   66.140</td> <td> 0.000</td> <td>   66.107</td> <td>   70.158</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>scale(center(Attack))</th>  <td>   11.2910</td> <td>    1.169</td> <td>    9.656</td> <td> 0.000</td> <td>    8.992</td> <td>   13.590</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>scale(center(Defense))</th> <td>    2.1099</td> <td>    1.169</td> <td>    1.804</td> <td> 0.072</td> <td>   -0.189</td> <td>    4.409</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>173.746</td> <th>  Durbin-Watson:     </th> <td>   1.890</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>1051.854</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.754</td>  <th>  Prob(JB):          </th> <td>3.92e-229</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>10.128</td>  <th>  Cond. No.          </th> <td>    1.67</td> \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}         &        HP        & \\textbf{  R-squared:         } &     0.268   \\\\\n",
       "\\textbf{Model:}                 &       OLS        & \\textbf{  Adj. R-squared:    } &     0.265   \\\\\n",
       "\\textbf{Method:}                &  Least Squares   & \\textbf{  F-statistic:       } &     72.79   \\\\\n",
       "\\textbf{Date:}                  & Fri, 15 Nov 2024 & \\textbf{  Prob (F-statistic):} &  1.17e-27   \\\\\n",
       "\\textbf{Time:}                  &     01:54:13     & \\textbf{  Log-Likelihood:    } &   -1776.2   \\\\\n",
       "\\textbf{No. Observations:}      &         400      & \\textbf{  AIC:               } &     3558.   \\\\\n",
       "\\textbf{Df Residuals:}          &         397      & \\textbf{  BIC:               } &     3570.   \\\\\n",
       "\\textbf{Df Model:}              &           2      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}       &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                                & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept}              &      68.1325  &        1.030     &    66.140  &         0.000        &       66.107    &       70.158     \\\\\n",
       "\\textbf{scale(center(Attack))}  &      11.2910  &        1.169     &     9.656  &         0.000        &        8.992    &       13.590     \\\\\n",
       "\\textbf{scale(center(Defense))} &       2.1099  &        1.169     &     1.804  &         0.072        &       -0.189    &        4.409     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 173.746 & \\textbf{  Durbin-Watson:     } &     1.890  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } &  1051.854  \\\\\n",
       "\\textbf{Skew:}          &   1.754 & \\textbf{  Prob(JB):          } & 3.92e-229  \\\\\n",
       "\\textbf{Kurtosis:}      &  10.128 & \\textbf{  Cond. No.          } &      1.67  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                     HP   R-squared:                       0.268\n",
       "Model:                            OLS   Adj. R-squared:                  0.265\n",
       "Method:                 Least Squares   F-statistic:                     72.79\n",
       "Date:                Fri, 15 Nov 2024   Prob (F-statistic):           1.17e-27\n",
       "Time:                        01:54:13   Log-Likelihood:                -1776.2\n",
       "No. Observations:                 400   AIC:                             3558.\n",
       "Df Residuals:                     397   BIC:                             3570.\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==========================================================================================\n",
       "                             coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------------------\n",
       "Intercept                 68.1325      1.030     66.140      0.000      66.107      70.158\n",
       "scale(center(Attack))     11.2910      1.169      9.656      0.000       8.992      13.590\n",
       "scale(center(Defense))     2.1099      1.169      1.804      0.072      -0.189       4.409\n",
       "==============================================================================\n",
       "Omnibus:                      173.746   Durbin-Watson:                   1.890\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1051.854\n",
       "Skew:                           1.754   Prob(JB):                    3.92e-229\n",
       "Kurtosis:                      10.128   Cond. No.                         1.67\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \"Cond. No.\" WAS 343.0 WITHOUT to centering and scaling\n",
    "import statsmodels.formula.api as smf\n",
    "model3_center_scale_fit.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "03856dd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>HP</td>        <th>  R-squared:         </th> <td>   0.148</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.143</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   34.40</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 15 Nov 2024</td> <th>  Prob (F-statistic):</th> <td>1.66e-14</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>01:54:13</td>     <th>  Log-Likelihood:    </th> <td> -1832.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   400</td>      <th>  AIC:               </th> <td>   3671.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   397</td>      <th>  BIC:               </th> <td>   3683.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "             <td></td>               <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>              <td>   69.3025</td> <td>    1.186</td> <td>   58.439</td> <td> 0.000</td> <td>   66.971</td> <td>   71.634</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>scale(center(Attack))</th>  <td>    8.1099</td> <td>    1.340</td> <td>    6.051</td> <td> 0.000</td> <td>    5.475</td> <td>   10.745</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>scale(center(Defense))</th> <td>    2.9496</td> <td>    1.340</td> <td>    2.201</td> <td> 0.028</td> <td>    0.315</td> <td>    5.585</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>284.299</td> <th>  Durbin-Watson:     </th> <td>   2.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>5870.841</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 2.720</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>20.963</td>  <th>  Cond. No.          </th> <td>    1.66</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}         &        HP        & \\textbf{  R-squared:         } &     0.148   \\\\\n",
       "\\textbf{Model:}                 &       OLS        & \\textbf{  Adj. R-squared:    } &     0.143   \\\\\n",
       "\\textbf{Method:}                &  Least Squares   & \\textbf{  F-statistic:       } &     34.40   \\\\\n",
       "\\textbf{Date:}                  & Fri, 15 Nov 2024 & \\textbf{  Prob (F-statistic):} &  1.66e-14   \\\\\n",
       "\\textbf{Time:}                  &     01:54:13     & \\textbf{  Log-Likelihood:    } &   -1832.6   \\\\\n",
       "\\textbf{No. Observations:}      &         400      & \\textbf{  AIC:               } &     3671.   \\\\\n",
       "\\textbf{Df Residuals:}          &         397      & \\textbf{  BIC:               } &     3683.   \\\\\n",
       "\\textbf{Df Model:}              &           2      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}       &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                                & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept}              &      69.3025  &        1.186     &    58.439  &         0.000        &       66.971    &       71.634     \\\\\n",
       "\\textbf{scale(center(Attack))}  &       8.1099  &        1.340     &     6.051  &         0.000        &        5.475    &       10.745     \\\\\n",
       "\\textbf{scale(center(Defense))} &       2.9496  &        1.340     &     2.201  &         0.028        &        0.315    &        5.585     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 284.299 & \\textbf{  Durbin-Watson:     } &    2.006  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } & 5870.841  \\\\\n",
       "\\textbf{Skew:}          &   2.720 & \\textbf{  Prob(JB):          } &     0.00  \\\\\n",
       "\\textbf{Kurtosis:}      &  20.963 & \\textbf{  Cond. No.          } &     1.66  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                     HP   R-squared:                       0.148\n",
       "Model:                            OLS   Adj. R-squared:                  0.143\n",
       "Method:                 Least Squares   F-statistic:                     34.40\n",
       "Date:                Fri, 15 Nov 2024   Prob (F-statistic):           1.66e-14\n",
       "Time:                        01:54:13   Log-Likelihood:                -1832.6\n",
       "No. Observations:                 400   AIC:                             3671.\n",
       "Df Residuals:                     397   BIC:                             3683.\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==========================================================================================\n",
       "                             coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------------------\n",
       "Intercept                 69.3025      1.186     58.439      0.000      66.971      71.634\n",
       "scale(center(Attack))      8.1099      1.340      6.051      0.000       5.475      10.745\n",
       "scale(center(Defense))     2.9496      1.340      2.201      0.028       0.315       5.585\n",
       "==============================================================================\n",
       "Omnibus:                      284.299   Durbin-Watson:                   2.006\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             5870.841\n",
       "Skew:                           2.720   Prob(JB):                         0.00\n",
       "Kurtosis:                      20.963   Cond. No.                         1.66\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from patsy import center, scale\n",
    "\n",
    "model3_linear_form_center_scale = \\\n",
    "  'HP ~ scale(center(Attack)) + scale(center(Defense))' \n",
    "model_spec3_center_scale = smf.ols(formula=model3_linear_form_center_scale,\n",
    "                                   data=pokeaman_train)\n",
    "model3_center_scale_fit = model_spec3_center_scale.fit()\n",
    "model3_center_scale_fit.summary()\n",
    "# \"Cond. No.\" is NOW 1.66 due to centering and scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "47b5b3d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>214.307</td> <th>  Durbin-Watson:     </th> <td>   1.992</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>2354.663</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 2.026</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>14.174</td>  <th>  Cond. No.          </th> <td>1.54e+16</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Omnibus:}       & 214.307 & \\textbf{  Durbin-Watson:     } &    1.992  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } & 2354.663  \\\\\n",
       "\\textbf{Skew:}          &   2.026 & \\textbf{  Prob(JB):          } &     0.00  \\\\\n",
       "\\textbf{Kurtosis:}      &  14.174 & \\textbf{  Cond. No.          } & 1.54e+16  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\end{center}"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.table.SimpleTable'>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model4_linear_form_CS = 'HP ~ scale(center(Attack)) * scale(center(Defense))'\n",
    "model4_linear_form_CS += ' * scale(center(Speed)) * Legendary' \n",
    "model4_linear_form_CS += ' * scale(center(Q(\"Sp. Def\"))) * scale(center(Q(\"Sp. Atk\")))'\n",
    "# Legendary is an indicator, so we don't center and scale that\n",
    "\n",
    "model4_CS_spec = smf.ols(formula=model4_linear_form_CS, data=pokeaman_train)\n",
    "model4_CS_fit = model4_CS_spec.fit()\n",
    "model4_CS_fit.summary().tables[-1]  # Cond. No. is 2,250,000,000,000,000\n",
    "\n",
    "# The condition number is still bad even after centering and scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "64ce291e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>214.307</td> <th>  Durbin-Watson:     </th> <td>   1.992</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>2354.663</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 2.026</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>14.174</td>  <th>  Cond. No.          </th> <td>1.54e+16</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Omnibus:}       & 214.307 & \\textbf{  Durbin-Watson:     } &    1.992  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } & 2354.663  \\\\\n",
       "\\textbf{Skew:}          &   2.026 & \\textbf{  Prob(JB):          } &     0.00  \\\\\n",
       "\\textbf{Kurtosis:}      &  14.174 & \\textbf{  Cond. No.          } & 1.54e+16  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\end{center}"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.table.SimpleTable'>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Just as the condition number was very bad to start with\n",
    "\n",
    "model4_CS_fit = model4_CS_spec.fit()\n",
    "model4_CS_fit.summary().tables[-1]  # Check condition number of the centered and scaled model\n",
    " \n",
    "    #Given code by prof did not work \n",
    "# model4_fit = model4.fit()\n",
    "# model4_fit.summary().tables[-1]  # Cond. No. is 12,000,000,000,000,000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8526251f",
   "metadata": {},
   "source": [
    "Model4_spec.exog is a transformed version of the original data, with added columns from interaction terms specified in model4_linear_form. This model as poor-out-of-sample prediction accuracy because there's high multicollinearity. This means that several predictors convey overlapping information, making it hard for the model to isolate the effect of individual predictors. This amplifies the model's sensitivty to small changes in data, undermining it's reliability and predictability. \n",
    "The impact high multicollinearity on out-of-sample generalization is, it inflates the in-sample R^2 because the model has more flexibility to fit the training data by overfitting on noise or spurious patterms. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d802a912",
   "metadata": {},
   "source": [
    "## Question 7 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d0cfd71d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'In sample' R-squared:     0.3920134083531893\n",
      "'Out of sample' R-squared: 0.30015614488652215\n",
      "'In sample' R-squared:     0.3326310334310908\n",
      "'Out of sample' R-squared: 0.29572460427079933\n",
      "'In sample' R-squared:     0.37818209127432456\n",
      "'Out of sample' R-squared: 0.35055389205977444\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>252.300</td> <th>  Durbin-Watson:     </th> <td>   1.953</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>3474.611</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 2.438</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>16.590</td>  <th>  Cond. No.          </th> <td>2.34e+09</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Omnibus:}       & 252.300 & \\textbf{  Durbin-Watson:     } &    1.953  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } & 3474.611  \\\\\n",
       "\\textbf{Skew:}          &   2.438 & \\textbf{  Prob(JB):          } &     0.00  \\\\\n",
       "\\textbf{Kurtosis:}      &  16.590 & \\textbf{  Cond. No.          } & 2.34e+09  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\end{center}"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.table.SimpleTable'>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here's something a little more reasonable...\n",
    "model5_linear_form = 'HP ~ Attack + Defense + Speed + Legendary'\n",
    "model5_linear_form += ' + Q(\"Sp. Def\") + Q(\"Sp. Atk\")'\n",
    "model5_linear_form += ' + C(Generation) + C(Q(\"Type 1\")) + C(Q(\"Type 2\"))'\n",
    "\n",
    "model5_spec = smf.ols(formula=model5_linear_form, data=pokeaman_train)\n",
    "model5_fit = model5_spec.fit()\n",
    "model5_fit.summary()\n",
    "yhat_model5 = model5_fit.predict(pokeaman_test)\n",
    "y = pokeaman_test.HP\n",
    "print(\"'In sample' R-squared:    \", model5_fit.rsquared)\n",
    "print(\"'Out of sample' R-squared:\", np.corrcoef(y,yhat_model5)[0,1]**2)\n",
    "# Here's something a little more reasonable...\n",
    "model6_linear_form = 'HP ~ Attack + Speed + Q(\"Sp. Def\") + Q(\"Sp. Atk\")'\n",
    "# And here we'll add the significant indicators from the previous model\n",
    "# https://chatgpt.com/share/81ab88df-4f07-49f9-a44a-de0cfd89c67c\n",
    "model6_linear_form += ' + I(Q(\"Type 1\")==\"Normal\")'\n",
    "model6_linear_form += ' + I(Q(\"Type 1\")==\"Water\")'\n",
    "model6_linear_form += ' + I(Generation==2)'\n",
    "model6_linear_form += ' + I(Generation==5)'\n",
    "\n",
    "model6_spec = smf.ols(formula=model6_linear_form, data=pokeaman_train)\n",
    "model6_fit = model6_spec.fit()\n",
    "model6_fit.summary()\n",
    "yhat_model6 = model6_fit.predict(pokeaman_test)\n",
    "y = pokeaman_test.HP\n",
    "print(\"'In sample' R-squared:    \", model6_fit.rsquared)\n",
    "print(\"'Out of sample' R-squared:\", np.corrcoef(y,yhat_model6)[0,1]**2)\n",
    "# And here's a slight change that seems to perhaps improve prediction...\n",
    "model7_linear_form = 'HP ~ Attack * Speed * Q(\"Sp. Def\") * Q(\"Sp. Atk\")'\n",
    "model7_linear_form += ' + I(Q(\"Type 1\")==\"Normal\")'\n",
    "model7_linear_form += ' + I(Q(\"Type 1\")==\"Water\")'\n",
    "model7_linear_form += ' + I(Generation==2)'\n",
    "model7_linear_form += ' + I(Generation==5)'\n",
    "\n",
    "model7_spec = smf.ols(formula=model7_linear_form, data=pokeaman_train)\n",
    "model7_fit = model7_spec.fit()\n",
    "model7_fit.summary()\n",
    "yhat_model7 = model7_fit.predict(pokeaman_test)\n",
    "y = pokeaman_test.HP\n",
    "print(\"'In sample' R-squared:    \", model7_fit.rsquared)\n",
    "print(\"'Out of sample' R-squared:\", np.corrcoef(y,yhat_model7)[0,1]**2)\n",
    "# And here's a slight change that seems to perhas improve prediction...\n",
    "model7_linear_form_CS = 'HP ~ scale(center(Attack)) * scale(center(Speed))'\n",
    "model7_linear_form_CS += ' * scale(center(Q(\"Sp. Def\"))) * scale(center(Q(\"Sp. Atk\")))'\n",
    "# We DO NOT center and scale indicator variables\n",
    "model7_linear_form_CS += ' + I(Q(\"Type 1\")==\"Normal\")'\n",
    "model7_linear_form_CS += ' + I(Q(\"Type 1\")==\"Water\")'\n",
    "model7_linear_form_CS += ' + I(Generation==2)'\n",
    "model7_linear_form_CS += ' + I(Generation==5)'\n",
    "\n",
    "model7_CS_spec = smf.ols(formula=model7_linear_form_CS, data=pokeaman_train)\n",
    "model7_CS_fit = model7_CS_spec.fit()\n",
    "model7_CS_fit.summary().tables[-1] \n",
    "# \"Cond. No.\" is NOW 15.4 due to centering and scaling\n",
    "# \"Cond. No.\" WAS 2,340,000,000 WITHOUT to centering and scaling\n",
    "model7_fit.summary().tables[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386335bf",
   "metadata": {},
   "source": [
    "model5_linear_form adds the effects of the predictors Attack, Defense, Speed, Legendary, Sp. Def, Sp. Atk, and categorical variables Generation, Type 1, and Type 2. This model is comprehensive, but runs the risk of multicollinearity due to many predictors and the high condition number.\n",
    "\n",
    "model6_linear_form simplifies the predictor set by removing Defense and Legendary and focuses on statistically significant predictors found in Model 5\n",
    "\n",
    "model7_linear_form adds interaction terms among the predictors, capturing more complex relationships.  It retains significant categorical indicators from model6_linear_form. However, this approach still raises the risk of multicollinearity due to the model complexity. \n",
    "\n",
    "model7_linear_form_CS uses centering and scaling to the main predictors while excluding categorical indicators. This reduces the change for multicollinearity by greatly reducing the condition number. This provides numerical stability without altering the effect of indicator variables. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca86fe61",
   "metadata": {},
   "source": [
    "## Question 8 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a1daf6",
   "metadata": {},
   "source": [
    "1. Randomly splitting the data gives us the change to get subsets that differ in their representativeness of the entire dataset. This can cause the regression model to perform either really well or really poorly depending on the split because of the specific composition of training and testing sets. Repeating this process multiple times can provide a more reliable picture of model performance\n",
    "\n",
    "2. Some splits yield a better out-of-sample performance if the test set is more representative. This arises purely from variability in the random split rather than model performance alone\n",
    "\n",
    "3. Sampling noise occurs due to the random split introducing differences in information available to the regression model between training and test sets.  A single split can be very misleading, so multiple random splits to estimate performance reliably is necessary. \n",
    "\n",
    "4. Repeatedly re-splitting the data can help us narrow down whether the instance of the out-of-sample R^2 being > the in-sample R^2 is persistent across splits or just a product of a specific split. If it persists, then the dataset might have structures of artifacts that influence the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e544fba5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.model_selection import train_test_split\n",
    "url = \"https://raw.githubusercontent.com/KeithGalli/pandas/master/pokemon_data.csv\"\n",
    "# fail https://github.com/KeithGalli/pandas/blob/master/pokemon_data.csv\n",
    "pokeaman = pd.read_csv(url)\n",
    "pokeaman\n",
    "# Linear form of model3_fit\n",
    "linear_form = 'HP ~ Attack + Defense'\n",
    "reps = 100  # Number of repetitions for re-sampling\n",
    "in_sample_Rsquared = np.zeros(reps)\n",
    "out_of_sample_Rsquared = np.zeros(reps)\n",
    "\n",
    "# Perform repeated sampling, fitting, and evaluation\n",
    "for i in range(reps):\n",
    "    # 50-50 train-test split (without fixed seed for variability)\n",
    "    pokeaman_train, pokeaman_test = train_test_split(pokeaman, train_size=0.5)\n",
    "    \n",
    "    # Fit model on training data\n",
    "    model_fit = smf.ols(formula=linear_form, data=pokeaman_train).fit()\n",
    "    \n",
    "    # Collect in-sample R-squared\n",
    "    in_sample_Rsquared[i] = model_fit.rsquared\n",
    "    \n",
    "    # Collect out-of-sample R-squared\n",
    "    y_test = pokeaman_test.HP\n",
    "    y_pred = model_fit.predict(pokeaman_test)\n",
    "    out_of_sample_Rsquared[i] = np.corrcoef(y_test, y_pred)[0, 1]**2\n",
    "\n",
    "# Create a DataFrame of results for visualization\n",
    "results_df = pd.DataFrame({\n",
    "    \"In Sample Performance (Rsquared)\": in_sample_Rsquared,\n",
    "    \"Out of Sample Performance (Rsquared)\": out_of_sample_Rsquared\n",
    "})\n",
    "\n",
    "# Scatter plot of in-sample vs. out-of-sample R-squared values\n",
    "fig = px.scatter(results_df, \n",
    "                 x=\"In Sample Performance (Rsquared)\", \n",
    "                 y=\"Out of Sample Performance (Rsquared)\",\n",
    "                 title=\"In-Sample vs Out-of-Sample R-squared Over Repeated Splits\",\n",
    "                 labels={\"In Sample Performance (Rsquared)\": \"In-Sample R-squared\",\n",
    "                         \"Out of Sample Performance (Rsquared)\": \"Out-of-Sample R-squared\"})\n",
    "\n",
    "# Add a y=x line for reference\n",
    "fig.add_trace(go.Scatter(x=[0, 1], y=[0, 1], name=\"y=x\", line=dict(dash=\"dash\")))\n",
    "\n",
    "# Display plot\n",
    "fig.show(renderer=\"png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377d5a38",
   "metadata": {},
   "source": [
    "## Question 9 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7539df07",
   "metadata": {},
   "source": [
    "Complex models, while they provide a better fit on training data or in some random train-test splits, are not guaranteed to perform as well in real-world scenarios where data is evolutionary and not stagnant. The simpler model offers more consistent generalizations (as seen in model6_fit) and better interpretability, and avoids the overfitting risks that is seen in the more complex model7_fit. This code emphasizes the principle of parsimony in model selection, where simpler models should be preferred unless you are in a situation where a complex model offers more consistency and significantly outperforms it in predictive accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd0c818",
   "metadata": {},
   "source": [
    "**ChatGPT Pre-Lecture Summary: https://chatgpt.com/share/67345685-2e78-8003-b24a-5cfb88693e58**\n",
    "\n",
    "Here’s a summary of our discussion today:\n",
    "\n",
    "   1. JupyterHub Markdown: We discussed how to add line breaks in JupyterHub Markdown cells using double spaces, <br> tags, and blank lines.\n",
    "\n",
    "   2. Loading the Titanic Dataset: You encountered a FileNotFoundError while trying to load titanic.csv. We resolved it by using the direct URL to the dataset hosted on GitHub. We also confirmed that the Embarked column needed renaming and adjustments to match the formula syntax.\n",
    "\n",
    "   3. Handling Categorical Variables: To fit a logistic regression model with categorical predictors like sex and embarked, we used pd.get_dummies() to create binary indicator columns. By setting drop_first=True, we avoided the dummy variable trap (multicollinearity).\n",
    "\n",
    "   4. Logistic Regression Interpretation:\n",
    "\n",
    "        a. We looked at how logistic regression coefficients differ from linear regression coefficients. In logistic regression, coefficients represent changes in the log-odds of an outcome, rather than direct outcome changes.\n",
    "\n",
    "        b. The odds ratio, derived from exponentiating coefficients, was also discussed. For instance, in the Titanic dataset, a negative coefficient for sex_male would indicate lower odds of survival for males.\n",
    "        \n",
    "5. Linear Regression Analogy for Logistic Regression:\n",
    "\n",
    "      a. We explored interpreting logistic regression as if it were multivariate linear regression. Here, coefficients for each predictor could be loosely interpreted as if they linearly influence survival, providing a helpful (though approximate) perspective.\n",
    "        \n",
    "      b. Using this analogy, we considered the Titanic dataset predictors (sex, age, and embarked), imagining their coefficients as if they linearly impacted survival, though logistic regression better models binary outcomes like survival probability.\n",
    "        \n",
    "6. Plotting Logistic Regression Results with Noise:\n",
    "\n",
    "    a. You requested a simulation of logistic regression results with added noise for the predictors. Using Plotly, we created code to plot the predicted probabilities for continuous and binary predictors, along with noisy data points to show variability.\n",
    "    \n",
    "    \n",
    "Overall, we covered a full workflow for logistic regression modeling in Python, including dataset loading, variable transformation, model fitting, and interpretation, all while addressing common technical issues and exploring alternative perspectives. Let me know if you'd like more details on any part!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4af368",
   "metadata": {},
   "source": [
    "**NotebookLM Summary**\n",
    "\n",
    "I used NotebookLM for pre-lecture ONLY, but I completely forgot to ask for a summary and I don't know how to acess old conversations. I've asked it how to do so and it is useless, so I looked online and saw that I should have saved the note. I thought NotebookLM saved chat history the same way ChatGPT does in case of a disconnection. That is my fault, I apologize."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e0478b",
   "metadata": {},
   "source": [
    "**ChatGPT Post-Lecture Summary (LINK: https://chatgpt.com/share/6734e211-6b3c-8003-bbc9-9e000bd44dec)**\n",
    "\n",
    "#### Summary: Model Complexity, Generalizability, and Interpretability in Multiple Linear Regression\n",
    "\n",
    "In this exercise, we explored the trade-offs between model complexity, interpretability, and generalizability in the context of multiple linear regression. Using a Pokémon dataset, we compared progressively complex models (model6_fit and model7_fit) to understand when a simpler model might be preferable over a more complex one, even if the latter shows higher predictive accuracy in certain scenarios.\n",
    "\n",
    "   1. Model Complexity and Overfitting:\n",
    "\n",
    "        (a) Model6: This simpler model includes a manageable number of predictors and fewer interactions, focusing on statistically significant predictors.\n",
    "        \n",
    "        (b) Model7: A more complex model with higher-order interactions, including a four-way interaction term (Attack:Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")). Although model7_fit initially showed better predictive performance than model6_fit, its complexity makes it more prone to overfitting, as it may capture idiosyncratic patterns specific to the training data.\n",
    "        \n",
    "   2. Evaluating Predictive Performance:\n",
    "\n",
    "        (a) In repeated random train-test splits, model7_fit outperformed model6_fit in \"out-of-sample\" $R^2$. However, this does not guarantee generalizability, as the higher complexity can lead to overfitting, capturing noise rather than true patterns.\n",
    "\n",
    "   3. The Importance of Generalizability:\n",
    "\n",
    "        (a) We then tested the models in a more realistic predictive setting, training them on data from earlier Pokémon generations and testing them on later generations. This simulates a real-world scenario where data arrives sequentially, and models trained on current data must generalize to future, unseen data.\n",
    "        \n",
    "        (b) When using only Generation 1 data for training, both models showed reduced out-of-sample performance on later generations. However, model7_fit exhibited a more significant decline, suggesting that its complexity made it less generalizable compared to the simpler model6_fit.\n",
    "        \n",
    "   4. Interpretability and Parsimony:\n",
    "\n",
    "        (a) Model interpretability is crucial in many applications. While complex models can sometimes yield better predictions, the increased number of interactions in model7_fit makes it challenging to interpret how each predictor influences the response variable (HP). In contrast, model6_fit is more straightforward, providing clear insights into the effects of individual predictors without excessive complexity.\n",
    "        \n",
    "        (b)Parsimonious models like model6_fit are often preferred when interpretability is important, as they strike a balance between simplicity and predictive power.\n",
    "   5. Conclusion:\n",
    "\n",
    "        (a) This exercise demonstrates that a simpler model can often be more desirable than a more complex one, especially when interpretability and generalizability are priorities. Although model7_fit initially seemed to offer better performance, the complex interactions it included made it more vulnerable to overfitting and less interpretable.\n",
    "        \n",
    "        (b) In summary, this analysis underscores the importance of choosing models that are as simple as possible while still meeting predictive goals. We should only opt for more complex models if they provide clear, consistent improvements in predictive performance across various testing scenarios.\n",
    "        \n",
    "This summary captures the main themes of model evaluation, emphasizing how a balance of simplicity, interpretability, and generalizability often outweighs raw predictive performance, especially in real-world settings. Let me know if you need further clarifications on any point!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6697cb",
   "metadata": {},
   "source": [
    "**ChatGPT Session 3 Post-Lecture Summary (LINK: https://chatgpt.com/share/6736aa34-57c4-8003-be91-5b44dad02635)**\n",
    "\n",
    "\n",
    "Here's a summary of what we've discussed today:\n",
    "\n",
    "   1. High Condition Numbers in Models:\n",
    "\n",
    "You mentioned that after centering and scaling your variables, the condition number of your regression model (using statsmodels) was still very high, indicating potential multicollinearity or numerical instability.\n",
    "I provided suggestions to handle high condition numbers, including checking for multicollinearity using Variance Inflation Factor (VIF), reducing the number of predictors, applying Principal Component Analysis (PCA), or using regularized regression models like Ridge or Lasso.\n",
    "Model Fitting Issues:\n",
    "\n",
    "You encountered an error where model4 was not defined when trying to access its summary. I suggested making sure you correctly define and fit the model before trying to access its summary, and provided an example of how to do so with model4_CS_spec.\n",
    "\n",
    "   2. Regression with Centered and Scaled Variables:\n",
    "\n",
    "You successfully defined a model where you centered and scaled certain variables (e.g., Attack, Defense, Speed, etc.) to improve the model's stability. This change led to a much lower condition number (from 343.0 to 1.66), indicating better numerical stability.\n",
    "Current Model Issue:\n",
    "\n",
    "You were attempting to access the summary of model3_fit, but the error occurred because the model variable wasn't defined. You later fixed this by using the correct variable, model3_center_scale_fit, for the centered and scaled regression model.\n",
    "\n",
    "Let me know if you would like further clarification or need additional help!\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
